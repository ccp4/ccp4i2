"""
CCP4i2 Report Generation Module

This module provides functions to generate reports for CCP4 crystallographic jobs.
Reports are generated by instantiating task-specific Report subclasses that parse
program output XML and produce structured report data for the frontend.

Key functions:
    - generate_job_report: Main entry point for generating job reports
    - get_report_job_info: Collects job metadata needed by report classes
    - simple_failed_report: Generates placeholder report for error cases

Report Discovery:
    Report classes are discovered via CTaskManager.getReportClass() which uses
    the report registry (core/task_manager/report_registry.py). Reports are
    lazy-loaded to minimize startup time.
"""
import logging
import pathlib
import os
import traceback
import xml.etree.ElementTree as ET
from typing import Optional, Dict, Any, List, Tuple

from ccp4i2.core.CCP4TaskManager import TASKMANAGER
from ccp4i2.core.CCP4Container import CContainer
from ccp4i2.core.base_object.fundamental_types import CList
from ccp4i2.core.CCP4TaskManager import CTaskManager
from ccp4i2.report.CCP4ReportParser import ReportClass
from ccp4i2.core import CCP4File
from ccp4x.db.models import Job, FileUse, File
from ..plugins.get_plugin import get_job_plugin
from ccp4x.db.ccp4i2_static_data import (
    PATH_FLAG_JOB_DIR,
    PATH_FLAG_IMPORT_DIR,
    FILETYPES_CLASS,
    FILETYPES_TEXT,
)


logger = logging.getLogger(f"ccp4x:{__name__}")


# Standard XML file search order for program output
XML_FILE_SEARCH_ORDER = ["program.xml", "XMLOUT.xml", "i2.xml"]


class ReportGenerationError(Exception):
    """Exception raised when report generation fails."""

    def __init__(self, message: str, task_name: str, details: Optional[str] = None):
        self.message = message
        self.task_name = task_name
        self.details = details
        super().__init__(f"{message} (task: {task_name})")


def simple_failed_report(
    reason: str, task_name: str, details: Optional[str] = None
) -> ET.Element:
    """
    Generate a minimal report indicating failure.

    Args:
        reason: Human-readable reason for failure
        task_name: Name of the task that failed
        details: Optional technical details (shown in smaller text)

    Returns:
        ET.Element: XML element tree for the failed report
    """
    details_html = ""
    if details:
        # Escape HTML entities in details
        escaped_details = (
            details.replace("&", "&amp;")
            .replace("<", "&lt;")
            .replace(">", "&gt;")
            .replace('"', "&quot;")
        )
        details_html = f'<pre style="font-size: 11px; color: #666; margin-top: 10px; white-space: pre-wrap;">{escaped_details}</pre>'

    return ET.fromstring(
        f"""<CCP4i2Report{task_name}_report xmlns:ns0="http://www.ccp4.ac.uk/ccp4ns" key="{task_name}_report_0" class="" style="overflow:auto;">
  <CCP4i2ReportTitle key="Title_112" class="" style="" title1="{reason}" title2="{reason}"/>
  <CCP4i2ReportDiv key="Div_0" class="" style="width:100%;border-width: 1px; border-color: black; clear:both; margin:0px; padding:0px;">
      <CCP4i2ReportGeneric key="Generic_1" class="" style="">
        <p style="font-size: 14">No report because: <em>{reason}</em></p>
        {details_html}
      </CCP4i2ReportGeneric>
  </CCP4i2ReportDiv>
</CCP4i2Report{task_name}_report>"""
    )


def get_report_job_info(job_id: str) -> Dict[str, Any]:
    """
    Collect all job information needed by report classes.

    Args:
        job_id: UUID of the job

    Returns:
        Dict containing job metadata, input files, output files, and filenames

    Raises:
        Job.DoesNotExist: If job with given UUID not found
    """
    job = Job.objects.get(uuid=job_id)
    result = _get_basic_job_info(job)
    result["inputfiles"] = list(_input_files(job))
    result["outputfiles"] = list(_output_files(job))
    result["filenames"] = _get_filenames(job)
    return result


def _get_basic_job_info(job: Job) -> Dict[str, Any]:
    """Extract basic job metadata for report generation."""
    result = {
        "status": Job.Status(job.status).label,
        "taskname": job.task_name,
        "taskversion": "1.0",
        "jobnumber": job.number,
        "projectid": str(job.project.uuid),
        "jobtitle": job.title,
        "creationtime": job.creation_time.timestamp(),
        "projectname": job.project.name,
        "fileroot": str(job.directory) + "/",
        "tasktitle": job.task_name,
        "jobid": str(job.uuid),
        "descendentjobs": _get_descendent_jobs(job),
    }
    # finishtime is required by CCP4ReportParser (JobDetails, JobLogFiles classes)
    # Use finish_time if available, otherwise fall back to creation_time
    if job.finish_time is not None:
        result["finishtime"] = job.finish_time.timestamp()
    else:
        result["finishtime"] = job.creation_time.timestamp()
    logger.debug("Basic job info: %s", result)
    return result


def _get_descendent_jobs(job: Job) -> List[Tuple[str, List[str]]]:
    """
    Get descendent jobs for pipeline report generation.

    Returns a list of tuples where each tuple represents a child job.
    Format: [(child_job_id, [grandchild_ids]), ...]

    This format allows iteration like:
        for descendentJob in jobInfo["descendentjobs"]:
            child_job_id = descendentJob[0]
    """
    result = []
    children = list(job.children.all())
    for child in children:
        grandchildren = list(child.children.all())
        grandchild_ids = [str(gc.uuid) for gc in grandchildren]
        result.append((str(child.uuid), grandchild_ids))
        # Recursively add grandchildren
        result.extend(_get_descendent_jobs(child))
    return result


def _input_files(job: Job):
    """Generate input file metadata for report."""
    # role=1 means INPUT files (role=0 is OUTPUT)
    for file_use in FileUse.objects.filter(job=job, role=1):
        try:
            path_flag = file_use.file.directory
            input_file = {
                "filetypeid": FILETYPES_TEXT.index(file_use.file.type.name),
                "filename": file_use.file.name,
                "annotation": file_use.file.annotation,
                "jobparamname": file_use.job_param_name,
                "jobid": str(file_use.file.job.uuid),
                "pathflag": file_use.file.directory,
                "filetype": file_use.file.type.name,
                "projectid": str(file_use.file.job.project.uuid),
                "jobnumber": file_use.file.job.number,
                "projectname": file_use.file.job.project.name,
                "filetypeclass": FILETYPES_CLASS[
                    FILETYPES_TEXT.index(file_use.file.type.name)
                ],
                "fileId": str(file_use.file.uuid),
            }
            if path_flag == PATH_FLAG_JOB_DIR:
                input_file["relpath"] = str(
                    pathlib.Path("CCP4_JOBS")
                    / os.path.join(
                        *[
                            f"job_{number}"
                            for number in file_use.file.job.number.split(".")
                        ]
                    )
                )
            elif path_flag == PATH_FLAG_IMPORT_DIR:
                input_file["relpath"] = "CCP4_IMPORTED_FILES"
            else:
                logger.warning(
                    "Invalid pathflag value: %s for file %s",
                    path_flag,
                    file_use.file.name,
                )
                continue
            yield input_file
        except (ValueError, AttributeError) as err:
            logger.warning(
                "Error processing input file %s: %s", file_use.file.name, err
            )
            continue


def _output_files(job: Job):
    """Generate output file metadata for report."""
    for file in File.objects.filter(job=job):
        try:
            output_file = {
                "filetypeid": FILETYPES_TEXT.index(file.type.name),
                "filename": file.name,
                "annotation": file.annotation,
                "jobparamname": file.job_param_name,
                "jobid": str(file.job.uuid),
                "pathflag": file.directory,
                "filetype": file.type.name,
                "projectid": str(file.job.project.uuid),
                "jobnumber": file.job.number,
                "projectname": file.job.project.name,
                "filetypeclass": FILETYPES_CLASS[FILETYPES_TEXT.index(file.type.name)],
                "fileId": str(file.uuid),
            }
        except ValueError as err:
            logger.warning("Error processing output file %s: %s", file.name, err)
            continue
        output_file["baseName"] = output_file["filename"]
        output_file["relpath"] = str(
            pathlib.Path("CCP4_JOBS")
            / os.path.join(*[f"job_{number}" for number in file.job.number.split(".")])
        )
        if output_file["pathflag"] == PATH_FLAG_IMPORT_DIR:
            output_file["relPath"] = "CCP4_IMPORTED_FILES"
        yield output_file


def _get_filenames(job: Job) -> Dict[str, Any]:
    """Extract filename mappings from job container."""
    try:
        plugin = get_job_plugin(job)
        if plugin is None:
            logger.warning("Failed to get plugin for job %s", job.uuid)
            return {}
        container: CContainer = plugin.container
        result_filenames = _get_input_filenames(container)
        result_filenames.update(_get_output_filenames(container))
        return result_filenames
    except Exception as err:
        logger.warning("Error getting filenames for job %s: %s", job.uuid, err)
        return {}


def _get_input_filenames(container: CContainer) -> Dict[str, Any]:
    """Extract input filenames from container."""
    if "inputData" in container.dataOrder():
        return {
            key: _get_filename(container.inputData.find(key))
            for key in container.inputData.dataOrder()
            if isinstance(container.inputData.find(key), CCP4File.CDataFile)
        }
    return {}


def _get_output_filenames(container: CContainer) -> Dict[str, Any]:
    """Extract output filenames from container."""
    if "outputData" in container.dataOrder():
        return {
            key: _get_filename(container.outputData.find(key))
            for key in container.outputData.dataOrder()
            if isinstance(container.outputData.find(key), CCP4File.CDataFile)
        }
    return {}


def _get_filename(data) -> Any:
    """Get filename(s) from a CDataFile or CList of CDataFiles."""
    if isinstance(data, CList):
        return [_path_if_exists(str(item)) for item in data]
    return _path_if_exists(str(data))


def _path_if_exists(path_str: str) -> str:
    """Return path string if file exists, empty string otherwise."""
    if pathlib.Path(path_str).exists():
        return path_str
    return ""


def _find_xml_file(
    job_directory: pathlib.Path, watch_file: Optional[str] = None
) -> Optional[pathlib.Path]:
    """
    Find the program output XML file for a job.

    Searches for XML files in the standard order:
    1. program.xml
    2. XMLOUT.xml
    3. i2.xml
    4. WATCHED_FILE (if specified)

    Args:
        job_directory: Path to the job directory
        watch_file: Optional watched file path from report metadata

    Returns:
        Path to the XML file if found, None otherwise
    """
    # Check standard XML files in order
    for xml_name in XML_FILE_SEARCH_ORDER:
        xml_path = job_directory / xml_name
        if xml_path.exists():
            logger.debug("Found XML file: %s", xml_path)
            return xml_path

    # Check watched file if specified
    if watch_file:
        watched_path = job_directory / pathlib.Path(watch_file)
        logger.debug("Checking watched file: %s", watched_path)
        if watched_path.exists():
            # For watched files, we return None to indicate no XML but job has output
            # The report class will handle this case
            return None

    return None


def generate_job_report(job: Job) -> ET.Element:
    """
    Generate a report for a given job using the CCP4i2 reporting system.

    This function:
    1. Looks up the appropriate Report class for the job's task type
    2. Finds the program output XML file
    3. Collects job metadata from the database
    4. Instantiates the Report class to generate the report

    Args:
        job: The Job model instance to generate a report for

    Returns:
        ET.Element: The generated report as an XML element tree.
        Returns a simple failed report if:
        - No report class found for the task
        - Required XML files not found
        - Report generation raises an exception

    Example:
        >>> job = Job.objects.get(uuid="...")
        >>> report_xml = generate_job_report(job)
        >>> ET.tostring(report_xml, encoding="unicode")
    """
    task_name = job.task_name
    job_directory = pathlib.Path(job.directory)

    logger.info(
        "Generating report for job %s (task: %s, status: %s)",
        job.uuid,
        task_name,
        Job.Status(job.status).label,
    )

    # Step 1: Get report class from registry
    task_manager: CTaskManager = TASKMANAGER()
    report_class = task_manager.getReportClass(name=task_name)

    if report_class is None:
        logger.error(
            "No report class found for task '%s'. "
            "Available reports: %s",
            task_name,
            task_manager.list_reports()[:10],  # First 10 for brevity
        )
        return simple_failed_report(
            f"No report class found for task '{task_name}'",
            task_name,
            details=f"Task '{task_name}' may not have a report implementation.\n"
            f"Check that a *_report.py file exists in the task's script directory.",
        )

    logger.debug("Using report class: %s", report_class.__name__)

    # Step 2: Check for watched file (for running job reports)
    watch_file = task_manager.getReportAttribute(task_name, "WATCHED_FILE")
    supports_running = task_manager.getReportAttribute(task_name, "RUNNING")
    logger.debug(
        "Report metadata - WATCHED_FILE: %s, RUNNING: %s", watch_file, supports_running
    )

    # Step 3: Find program output XML
    xml_path = _find_xml_file(job_directory, watch_file)

    # If no XML found and no watched file, we can't generate a report
    if xml_path is None and watch_file is None:
        searched_files = ", ".join(XML_FILE_SEARCH_ORDER)
        logger.warning(
            "No program XML found in %s. Searched: %s", job_directory, searched_files
        )
        return simple_failed_report(
            "No program XML found",
            task_name,
            details=f"Job directory: {job_directory}\n"
            f"Searched for: {searched_files}\n"
            f"Job status: {Job.Status(job.status).label}",
        )

    # Step 4: Parse XML if we have one
    # Use retry logic to handle rare race conditions with atomic writes
    output_xml = None
    if xml_path is not None:
        import time
        max_retries = 3
        retry_delay = 0.1  # 100ms between retries
        last_error = None

        for attempt in range(max_retries):
            try:
                output_xml = ET.parse(xml_path).getroot()
                logger.debug("Parsed XML file: %s", xml_path)
                break
            except ET.ParseError as err:
                last_error = err
                if attempt < max_retries - 1:
                    logger.warning(
                        "XML parse attempt %d failed for %s, retrying: %s",
                        attempt + 1, xml_path, err
                    )
                    time.sleep(retry_delay)
                else:
                    logger.error("Failed to parse XML file %s after %d attempts: %s",
                                 xml_path, max_retries, err)
                    return simple_failed_report(
                        "Failed to parse program XML",
                        task_name,
                        details=f"File: {xml_path}\nError: {err}",
                    )

    # Step 5: Collect job info from database
    try:
        report_job_info = get_report_job_info(job.uuid)
    except Exception as err:
        logger.error("Failed to get job info for %s: %s", job.uuid, err)
        return simple_failed_report(
            "Failed to collect job information",
            task_name,
            details=f"Job UUID: {job.uuid}\nError: {err}",
        )

    # Step 6: Determine if report should be standardised
    status = Job.Status(job.status).label
    non_standardise_statuses = [
        "Running",
        "Running remotely",
        "Pending",
        "Unknown",
        "Queued",
    ]
    standardise = status not in non_standardise_statuses

    # Step 7: Instantiate report class
    try:
        logger.debug(
            "Creating report instance (standardise=%s, status=%s)", standardise, status
        )
        report: ReportClass = report_class(
            xmlnode=output_xml,
            jobInfo=report_job_info,
            standardise=standardise,
            jobStatus=status,
            jobNumber=job.number,
            xrtnode=None,
            projectId=str(job.project.uuid).replace("-", ""),
        )

        # Step 8: Generate report XML
        report_etree = report.as_data_etree()
        logger.info("Successfully generated report for job %s", job.uuid)
        return report_etree

    except Exception as err:
        # Log full traceback for debugging
        logger.error(
            "Report generation failed for job %s (task: %s): %s\n%s",
            job.uuid,
            task_name,
            err,
            traceback.format_exc(),
        )
        return simple_failed_report(
            "Report generation failed",
            task_name,
            details=f"Task: {task_name}\n"
            f"Job: {job.number}\n"
            f"Error: {err}\n\n"
            f"See server logs for full traceback.",
        )
