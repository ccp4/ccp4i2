<!DOCTYPE HTML PUBLIC "-//IETF//DTD HTML//EN">
<html> <head>
<title>CCP4I2 Developers Wrappers and Pipelines</title>
</head>

<body>
<h1>CCP4I2 Developers: Wrappers and Pipelines</h1>

<h3>Contents</h3>
<p>
<a href="#introduction">Introduction</a>
<br/><a href="#input output data">Input and Output Data</a>
<br/><a href="#wrapper example">A Simple Wrapper Example- <i>pdbset</i></a>
<br/><a href="#methods">The main CPluginScript methods</a>
<br/><a href="#pipeline example">A Simple Pipeline Example - <i>demo_copycell</i></a>
<br/><a href="#file organisation">Pipeline and Wrapper File Organisation</a>
<br/><a href="#unittests">Unittests for Wrappers and Pipelines</a>
<br/><a href="#testing">Testing and Debugging Scripts</a>
<br/><a href="#miniMTZs">Handling Mini-MTZs</a>
<br/><a href="#CPluginScript"><i>CPluginScript</i> Class Documentation</a>
<br/><a href="#moving data">Moving Data Between Plugins</a>
<br/><a href="#running processes">Asynchronous Pipelines</a>
<br/><a href="#connectSignal">Connecting a pipeline with connectSignal()</a>
<br/><a href="#internal">A 'Wrapper' that does not run an External Process</a>
<br/><a href="#interrupt-restart">Interrupting and restarting processes</a>
<br/><a href="#performance_indicators">Performance Indicators</a>
<br/><a href="#project_defaults">Project Defaults</a>
<br/><a href="#non-i2">Incorporating non-CCP4i2 pipelines</a>
<br/><a href="#exporting_task">Exporting a task as a compressed file</a>
<br/><a href="#export_file_menu">Exporting files from a job</a>
<br/><a href="#temp">Temporary files and cleanup</a>
<br/>Appendices
<br/><a href="parents">Parents</a>
<br/><a href="file_organisation">File Organisation</a>
<br/><a href="#process_manager">The Process Manager</a>
<br/><a href="#xml_files">XML Files</a>
</p>

<a name="introduction"/><h3>Introduction</h3>

<p> To make a program or script available in CCP4i2 it must be 'wrapped' in a Python script that is a sub-class of the <i>CPluginScript</i> class. <i>CPluginScript</i> provides methods to handle parameters, run programs, maintain an error report and record progress to a database so writing a simple script requires very minimal lines of code.  We usually call a script that runs just one program a 'wrapper'; and a 'pipeline' is a script that calls two or more wrappers in order to run multiple programs. We also refer to either wrappers or pipelines as 'plugins'. We hope that developers will contribute wrappers to the <i>ccp4i2/wrappers</i> directory to be available to all pipeline developers and the GUI. This is the place to look for examples to follow. There is a separate <i>ccp4i2/pipelines</i> directory for contributed pipelines. </p>
<p>For each script we need to clearly define the interface (i.e. the parameters that are passed into the script); this is vital both for communication with the GUI and for enabling the database to track the provenance of crystallographic data. The parameters of the script interface must follow the CCP4i2 data model that has classes for all the common crystallographic data (well we are working on it!). These parameters are listed in a <i>DEF</i> file; this is an XML file (see <a href="#xml_files">appendix</a>) and there is one for each <i>CPluginScript</i> script file. The <i>DEF</i> can be created by hand-editing but can more easily be created by the developer using the <i>defEd</i> GUI that provides a list and documentation for all the classes of the CCP4i2 data model. Note that the <i>DEF</i> file is a definition of the parameters; it does not contain the actual values for parameters.<p>
<p>Most <i>CPluginScript</i> scripts are made accessible in the  CCP4i2 GUI. The GUI uses the same data model as the scripts and has widgets to represent each data class so a GUI for the script can be auto-generated from the <i>DEF</i> file. The auto-generated GUI is useful for testing purposes; a better structured and more attractive GUI can be written based on the <i>DEF</i> file. When a job is run the GUI writes an <i>input_params</i> file that contains the values of parameters that are passed to the script.</p>

<p>The biggest job in creating a wrapper script is usually generating an input command file to the program that is correctly formatted and interprets the parameters passed to the script. The easiest way to do this is to write a template for the program command file and then use the <i>CComTemplate</i> class to interpret the template and the script parameters to create a program command file.</p>

<p>In the CCP4i2 GUI the scripts are referred to as 'tasks' and every time the user runs a task it is called a 'job'. If a <i>CPluginScript</i> calls another <i>CPluginScript</i> then this is called a 'sub-job'. The CCP4I2 database records all jobs and any sub-jobs and the input and output data for each job. This input and output data is mostly in the form of references to PDB and MTZ files but other data (usually referred to as 'extra' data) is also recorded. The database is notified when a job is started and when it finishes. When a job starts from the GUI the database is notified automatically. When a <i>CPluginScript</i> script calls other scripts it should use the <i>makePluginObject()</i> method that instantiates the new <i>CPluginScript</i>, passes necessary 'database' information to the new object and notifies the database that a sub-job is started. The completion of jobs is notified by the <i>reportStatus()</i> method that is called by the base class <i>postProcess()</i> method. The <i>reportStatus()</i> method also saves the script's parameters to a <i>PARAMS</i> file that is read automatically to load the appropriate data to the database. The <i>PARAMS</i> file has the same format and mostly the same content as the <i>input_params</i> file but may contain additional 'output' information.</p>

<p><i>CPluginScript</i> maintains a list of all errors or warnings generated within the class or by functions called from the class. This serves as a complete log - note that it is possible to add 'error' reports that are not an error (severity is SEVERITY_OK).</p>

<a name="input output data"/><h3>Input and Output Data</h3>

<p>Firstly to sort out a naming convention. There are two sorts of xml file that are relvant here: the 'def' file is a definition of the parameters and the 'params' file contain actual data for a particular job. I used to call the 'params' file a 'data' file but that is confusing with the real data files such as PDB/MTX.</ip>

<p>The contents of a def file are split into three or four sub-containers. It is very important that data is put in the right sub-container. The <i>inputData</i> and <i>outputData</i> containers are for the input and output experimental data and model data. This is usually the PDB and MTZ files but is also the 'extra' data such as NCS and domains which are an essential part of the description of the model.  The <i>controlParameters</i> subcontainer should contain just about everything else. Parameters relevant for implementation of the gui go in the <i>guiAdmin</i> sub-container.</p>
<p>The contents of the <i>inputData</i> and <i>outputData</i> define the <i>signature</i> of a script and is vital for the correct management of the data in the overall i2 system. Many programs can have alternative input and output dependent on the exact function. As a general principle we could say that the different signatures ought to be treated as different tasks in CCP4i2 and so should have different wrappers. There are probably good reasons for not totally enforcing that principle and writing multiple wrappers is inefficient. See how it goes.<p>
<p>The GUI automatically populates the input data based on the previous jobs but the user can override this and select files or data. The task interfaces do not allow the user to set output data - the user can export (i.e. copy) files after the job is finished. The GUI will write a params file, <i>whatever.input_params.def.xml</i> that is read by the wrapper (this is done automatically as the wrapper is instatiated).   The names of output files are set automatically by <i>CPluginScript.checkOutputData()</i> method that is called as part of the base class <i>process()</i> method and if you reimplement this then you must ensure that <i>checkOutputData()</i> is called before <i>makeCommandAndScript()</i>. The <i>makeCommandAndScript()</i> will pass-on the names of ouput files to the program arguments or input file. The ouput data that does not go into a file, i.e. the 'extra' data must be handled by the script. What needs doing will depend on the data and the program but typically files might need to be copied to the 'correct' path specified by the <i>outputDta</i> params and other data might be read from the program log file and loaded into the appropriate <i>outputData</i> parameters. The updated version of the parameters are written to a file <i>whatever.params.xml</i> by the <i>CPluginScript.saveParams()</i> method that is called as part of <i>CPluginScript.postProcess()</i>. The main GUI process extracts the  ouput data from this file and saves to the database.</p>
<p>It is obviously important to identify the 'extra' data that is passed between programs and to use a standard data model.</p>

<a name="wrapper example"/><h3>A Simple Wrapper Example - <i>pdbset</i></h3>

<p>This wrapper changes the cell parameter in a PDB file using the <i>pdbset</i> program. (A better way to do this now would use Python interface to <i>mmdb</i> library). The input to the script is a PDB file name and cell values. The output is another PDB file name. The DEF file to define the script parameters is <a href="../../wrappers/pdbset/script/pdbset.def.xml"><i>$CCP4I2/wrappers/pdbset/script/pdbset.def.xml</i></a> which contains (excluding the meta-data header):

<pre>
    &lt;container id="inputData"&gt;
      &lt;content id="XYZIN"&gt;
        &lt;className&gt;CPdbDataFile&lt;/className&gt;
        &lt;qualifiers&gt;
           &lt;mustExist&gt;True&lt;/mustExist&gt;
        &lt;/qualifiers&gt;
      &lt;/content&gt;
      &lt;content id="CELL"&gt;
        &lt;className&gt;CCell&lt;/className&gt;
      &lt;/content&gt;
    &lt;/container&gt;
    &lt;container id="outputData"&gt;
      &lt;content id="XYZOUT"&gt;
        &lt;className&gt;CPdbDataFile&lt;/className&gt;
      &lt;/content&gt;
    &lt;/container&gt;
    &lt;container id="controlParameters"&gt;
    &lt;/container&gt;
</pre>

<p>The two important types of element in this XML are &lt;container&gt; and &lt;content&gt;. The <i>container</i> is used to group together the parameters into three groups: <i>inputData</i>, <i>controlParameters</i> and <i>outputData</i> (this example does not have any <i>controlParameters</i>). The <i>content</i> elements specify the name (as the id attribute), data class (as <i>className</i> element), and <i>qualifiers</i> for each parameter. So, for example, the <i>XYZIN</i> parameter is class <i>CPdbDataFile</i> and has a qualifier <i>mustExist</i> that is <i>True</i> (which means the file must exist for the the <i>CPdbDataFile</i> to be valid). A file like this can be created using the <i>defEd</i> GUI.</p>

<p>When a script is run from CCP4i2 a <i>input_params</i> parameter file is created by the GUI and for <i>pdbset</i> has the form (excluding the meta-data header):</p>

<pre>
    &lt;inputData&gt;
      &lt;XYZIN&gt;
        &lt;project&gt;my_project&lt;/project&gt;
        &lt;baseName&gt;broken.pdb&lt;/baseName&gt;
        &lt;relPath/&gt;
      &lt;/XYZIN&gt;
      &lt;CELL&gt;
        &lt;a&gt;64.897&lt;/a&gt;
        &lt;b&gt;78.323&lt;/b&gt;
        &lt;c&gt;38.792&lt;/c&gt;
        &lt;alpha&gt;90.0&lt;/alpha&gt;
        &lt;beta&gt;90.0&lt;/beta&gt;
        &lt;gamma&gt;90.0&lt;/gamma&gt;
      &lt;/CELL&gt;
    &lt;/inputData&gt;
    &lt;outputData&gt;
      &lt;XYZOUT&gt;
        &lt;project&gt;&lt;/project&gt;
        &lt;baseName&gt;&lt;/baseName&gt;
        &lt;relPath&gt;&lt;/relPath&gt;
      &lt;/XYZOUT&gt;
    &lt;/outputData&gt;
    &lt;controlParameters/&gt;
</pre>

<p>This file follows the structure specified in the DEF file with containers <i>&lt;inputData&gt;</i>and  <i>&lt;outputData&gt;</i>, and parameters XYZIN, CELL and XYZOUT. Note that no value has been given for XYZOUT.</p>

<p>The actual script to run <i>pdbset</i> is in the file <a href="../../wrappers/pdbset/script/pdbset.py"><i>$CCP4I2/wrappers/pdbset/script/pdbset.py</i></a> and is:

<pre>
from core.CCP4PluginScript import CPluginScript
     
class pdbset(CPluginScript):

    TASKMODULE = 'utility'
    TASKTITLE = 'PDBSet'
    TASKNAME = 'pdbset'
    TASKCOMMAND = 'pdbset'
    TASKVERSION= 0.0
    COMLINETEMPLATE = '''1 XYZIN $XYZIN XYZOUT $XYZOUT'''
    COMTEMPLATE = '''1 CELL $CELL.a $CELL.b $CELL.c $CELL.alpha $CELL.beta $CELL.gamma
1 END'''
</pre>

<p>The <i>pdbset</i> class is a sub-class of <i>CPluginScript</i> and requires only that some class attributes are set for the base class methods to do the all the work. The class attribute TASKMODULE and TASKTITLE specify how the script appears in the GUI and TASKVERSION is a version for the script. Information to run the program is: TASKCOMMAND - the name of the executable; COMLINETEMPLATE - a template for the command line; 
COMTEMPLATE - a template for the program command file. The templates are described in more detail <a href="./command_templates.html">here</a> but two important point:</p>
<ul>
  <li>The first word on a line is evaluated (it could be a parameter or a short Python script) and if it is true then the line is written to the command file.</li>
  <li>Any word beginning with $ is substituted by the value of the parameter.</li>
</ul>
<a name="methods"/><h3>The main <i>CPluginScript</i> methods</h3>
<p>The <i>CPluginScript.__init__()</i> method creates a container (a <a href="./data_classes.html#containers">CContainer</a> object) and reads the script's DEF file to specify the allowed contents of the container; note that this does not specify the actual parameter values. The parameter values can be passed to the container programmatically (if the script is been run from another pipeline script) or are read from a file. When a script is run from CCP4i2 a PARAMS file (<i>input_params.xml</i>) is created by the GUI and loaded by the <i>CPluginScript.__init__()</i> method.</p>

<p>The <i>CPluginScript.process()</i> method does most of the work. It calls the following methods:</p>
<ul>
  <li><i>checkInputData()</i> - checks that data in the <i>inputData</i> container is valid and will cause the script to fail if it is not so. Particularly this checks that the input files exist and return a list of invalid file parameters.</li>
  <li><i>checkOutputData()</i> - checks that output files have valid names. Usually the GUI does not provide output file names and this method will set appropriate file names. This method is expected to fix things and not cause the script to fail.</li>
  <li><i>processInputFiles()</i> - The base class method does nothing but many scripts will need to reimplement this method - see below.</li>
  <li><i>makeCommandAndScript()</i> - The base class method uses the COMLINETEMPLATE and COMTEMPLATE templates to generate the program command line and command file. As an alternative to providing these templates a script developer can reimplement the <i>makeCommandAndScript()</i> method.</li>
  <li><i>startProcess()</i> - uses the PROCESSMANAGER module to start the program executable specified by TASKCOMMAND in another process. The command line and file create by <i>makeCommandAndScript()</i> are used.This is reimplemented for classes that do not run an external process.</li>
</ul>
<p>When the program run is finished the <i>postProcess()</i> method is called. This calls three other methods:</p>
<ul>
  <li><i>postProcessCheck()</i> - retrieves information from the PROCESSMANAGER to find out if the program process ran successfully. It returns CPluginScript.SUCCEEDED or CPluginScript.FAILED.</li>
  <li><i>processOutputFiles()</i> - The base class method does nothing but many scripts will need to reimplement this method - see below.</li>
  <li><i>reportStatus()</i> - this does three things:
    <ul>
      <li>Saves the parameters from the container to a PARAMS file.  These parameters will be similar to the <i>input_params</i> file, if it exists, but could include output file names added by <i>checkOutputData()</i> or any changes to parameters made by more sophisticated scripts.</li>
      <li>Reports the jobs completion to the database.</lI>
      <li>Emits a signal to say it has finished that may be received by a controlling pipeline script.</li>
      </ul>
    </li>
</ul>

<p>Normally a wrapper may need to reimplement:
<ul>
  <li><i>processInputFiles()</i> to perform any manipulations on input data or files before calling the main program</li>
  <li><i>processOutputFiles()</i>  to perform any manipulations on output data or files after the program has run</li>
  <li><i>makeCommandAndScript()</i> to create the command line and script that will run the program</li>
</ul>
<p>All of these methods must return either <i>CPluginScript.SUCCEEDED</i> or <i>CPluginScript.FAILED</i> which will determine whether the script will continue running or will abort. There is a third possible return status for <i>processOutputFiles()</i>: <i>CPluginScript.UNSATISFACTORY</i> for when the job has run without error but not produced a useful result. This return flag leads to an 'Unsatisifactory' database status for the job and the job is presented differently in the GUI: the icon on the Job List indicates it is unsatisfactory but the normal job report is presented (rather than the generic failed job report.).  The job report creation code is initialised with the status flag 'Unsatisfactory' and should provide an appropriate report. </p> 
<p>For pipelines it is necessary to reimplement the <i>process()</i> method to call the sub-tasks but it should not be necessary to re-implement <i>process()</i> or <i>postProcess()</i> methods for wrappers. If you have a wrapper issue that can not be addressed with the three methods above please talk to Liz.</p>

<p>The </i>CPluginScript</i> process handling will handle the case of an externally run program clearly failing (i.e. the Process Manager has a 'failed' error code - see <a href="#process_manager">the Process Manager appendix</a> but does not check the exit status of the external process as the output from differnt programs is unpredictable. The task implementer can do this in the <i>processOutputFiles()</i> method and should make an error report before returning a CPluginScipt.FAILED:</p>

<pre>
from core.CCP4Modules import PROCESSMANAGER

class myPluginScript(CPluginScript):
  ERROR_CODES = { 201 : {'description' : 'My program failed with error code' } }

  ...

  def processOutputFiles(self):
    exitStatus = PROCESSMANAGER().getJobData(pid=self.getProcessId(),attribute='exitStatus')
    if exitStatus != 0:     #Beware what is expect from given program and os?
      self.appendErrorReport(201,'Exit status: '+str(exitStatus))
      return CPluginScipt.FAILED

    ....
</pre>
<p>See also the <a href="./error_handling.html#plugins">error handling in plugins</a>.


<a name="pipeline example"/><h3>A Simple Pipeline Example - <i>demo_copycell</i></h3>
<p>This is a demo of the usual <i>mtzdump</i> and <i>pdbset</i> pipeline that uses <i>mtzdump</i> to extract the cell parameters from an MTZ file and <i>pdbset</i> to set these cell parameters in a PDB file. This would not be the recommended way to achieve this result - there are much simpler Python tools!  To run this script from the gui go to <i>ccp4i2/qtgui/CCP4TaskManager.py</i> and change the parameter <i>SHOW_WRAPPERS</i> (near the top of the file) to <i>True</i> so the <i>Demo copy cell</i> task is displayed in the <i>Test code for developers only</i> module at the bottom of the <i>Task menu</i>. Note this script does not have a good report generator so there is no report.</p>
<p>The code is in <a href="../../wrappers2/demo_copycell/script/demo_copycell.py"><i>$CCP4I2/wrappers2/demo_copycell/script/demo_copycell.py</i></a> and looks like this:</p>

<pre>
class demo_copycell(CPluginScript):

    TASKMODULE = 'utility'
    TASKTITLE = 'Demo copy cell'
    TASKNAME = 'demo_copycell'
    TASKVERSION= 0.0
    ASYNCHRONOUS=True

    def process(self):
      
      # Check all input files exist
      nonExFiles = self.checkInputData()
      if len(nonExFiles)>0:
        self.reportStatus(CPluginScript.FAILED)
        return

      # Provide default output file names if necessary
      self.checkOutputData()

      # Create instance of mtzdump class (and get it registered with the database)
      self.mtzdump = self.makePluginObject('mtzdump')
      self.mtzdump.container.inputData.HKLIN = self.container.inputData.HKLIN
      # Run mtzdump to get the cell parameters
      self.connectSignal(self.mtzdump,'finished',self.process_1)
      self.mtzdump.process()

</pre>

<p>The TASKMODULE and TASKTITLE attributes are provided so the script can be placed in the GUI but there are no TASKCOMMAND, COMTEMPLATE or COMLINETEMPLATE attributes defined. The <i>process()</i> method calls <i>checkInputData()</i> and <i>checkOutputData()</i>. <i>checkInputData()</i> returns a list of names of non-existant input files. If this list has length greater than zero then <i>reportStatus()</i> is called with a failed status and the method returns. An instance of <i>mtzdump</i> is created using the <i>makePluginObject()</i> method. The only data <i>mtzdump</i> needs is the input MTZ file, HKLIN; this parameter value is copied from the  <i>demo_copycell</i> container to the  <i>mtzdump</i> container. Before running <i>mtzdump.process()</i> the <i>self.connectSignal()</i> method is called to ensure that when <i>mtzdump</i> finishes (and emits a finished signal) the next method in the pipeline (<i>process_1()</i>) is called.
<p>When mtzdump finishes (by calling <i>postProcess()</i>) it emits a signal with an additional status parameter that is either <i>CPluginScript.SUCCEEDED</i> or <i>CPluginScript.FAILED</i>. The <i>demo_copycell.process_1</i> has an argument for the status:</p>

<pre>
    def self.process_1(self,status):
      if status == CPluginScript.FAILED:
        self.reportStatus(status)
        return

      # Create an instance of pdbset and copy parameters
      self.pdbset = self.makePluginObject('pdbset')
      self.pdbset.container.inputData.XYZIN = self.container.inputData.XYZIN
      self.pdbset.container.inputData.CELL = self.mtzdump.container.outputData.CELL
      self.pdbset.container.outputData.XYZOUT = self.container.outputData.XYZOUT

      # run pdbset
      self.connectSignal(self.pdbset,'finished',self.postProcessWrapper)
      self.pdbset.process()
</pre>

<p><i>process_1()</i> first checks the wrapper exit status and finishes if the wrapper failed. It then creates an instance of the <i>pdbset</i> wrapper and copies the appropriate parameter values to the pdbset container. It then runs the <i>pdbset.process()</i> method after connecting the finish signal to the <i>CPluginScript.postProcessWrapper()</i> method. <i>postProcessWrapper()</i> accepts the exit status from the wrapper and finishes the pipeline appropriately.</p>
<p>The above script runs asynchronously - after the <i>mtzdump</i> and pdbset sub-tasks are started by calling <i>process()</i> it does not wait for then to complete. This is discussed further <a href="#running processes">below<a>. The alternative approach of would lead to simpler code with only one <i>process()</i> method:</p>

<pre>
    ASYNCHRONOUS=False

    def process(self):
      
      # Check all input files exist
      nonExFiles = self.checkInputData()
      if len(nonExFiles)>0:
        self.reportStatus(CPluginScript.FAILED)
        return

      # Provide default output file names if necessary
      self.checkOutputData()

      # Create instance of mtzdump class (and get it registered with the database)
      self.mtzdump = self.makePluginObject('mtzdump')
      self.mtzdump.container.inputData.HKLIN = self.container.inputData.HKLIN
      # Run mtzdump to get the cell parameters
      status = self.mtzdump.process()
      if status == CPluginScript.FAILED:
        self.reportStatus(status)
        return

      # Create an instance of pdbset and copy parameters
      self.pdbset = self.makePluginObject('pdbset')
      self.pdbset.container.inputData.XYZIN = self.container.inputData.XYZIN
      self.pdbset.container.inputData.CELL = self.mtzdump.container.outputData.CELL
      self.pdbset.container.outputData.XYZOUT = self.container.outputData.XYZOUT

      # run pdbset
      status = self.pdbset.process()
      if status == CPluginScript.FAILED:
        self.reportStatus(status)
        return

      return CPluginScript.SUCEEDED
</pre>

<p>Here the <i>ASYNCHRONOUS</i> attribute is set <i>False</i> to inform the core system how to run this and there is not need for calls to <i>connectSignal()</i>. The sub-task <i>process()</i> method returns a status flag, either <i>FAILED</i> or <i>SUCCEEDED</i> and if this is <i>FAILED</i> then the pipeline should either handle the problem or terminate itself by calling <i>self.reportStatus(status)</i>. The <i>process()</i> method itself should return <i>SUCCEEDED</i> or <i>FAILED</i>.
</p>


<a name="file organisation"/><h3>Pipeline and Wrapper File Organisation</h3>
<p>The CCP4I2 directory has a <i>wrapper</i> sub-directory to which can be added wrapper scripts. Each script has its own directory with <i>script</i> and <i>test_data</i> sub-directories. The script directory should contain a <i>wrapper</i>.py file containing the <i>CPluginScript</i> script and a  <i>wrapper</i>.def.xml file. There is a <i>test_data</i> directory for any data needed to test the script. So the part of the <i>wrapper</i> directory for the two demo wrappers:</p>
<pre>
   ccp4i2 - wrappers - mtzdump - script ---- mtzdump.py
                    |         |        |
                    |         |         ---- mtzdump.def.xml
                    |         |
                    |          - test_data - gere_nat.mtz
                    |                     |
                    |                      - mtzdump.xml
                    |
                     -- pdbset - script ---- pdbset.py
                              |        |
                              |         ---- pdbset.def.xml
                              |
                                - test_data - 1df7.pdb
</pre>
<p>There is a slightly more complicated directory structure for pipelines which should allow for  developers' more varied requirements when developing a pipeline. The <i>defEd</i> utility will create the directory structure for a new wrapper or pipeline (look under the <i>Tools</i> menu).</p>
<p>There is no technical difference between the <i>wrappers</i> and <i>pipelines</i> directories but the understanding that developers are encouraged to use code in <i>wrappers</i> and extend its functionality if necessary.  There is also a <i>wrappers2</i> directory for some unconventional wrappers used by the core system.</p>


<a name="unittests"/><h3>Unittests for Wrappers and Pipelines</h3>
<p>Unittests are useful for testing the non-graphical scripts particularly while in development but <a href='./project_based_testing.html'>project based testing</a> is now preferred.</p>
<p>The CCP4i2 core code uses the standard Python <i>unittest</i> module for testing (see the <a href="http://docs.python.org/release/2.6.6/library/unittest.html">Python documentation</a>). There are currently a couple of issues to running a <i>CPluginScript</i>s in <i>unittest</i>:</p>
<ul>
<li> <i>CPluginScript</i> requires that Qt <i>QApplication</i> is created </li>
<li> The default mode for the PROCESSMANAGER running a process is asynchronously - this does not play nicely with <i>unittest</i> so it must be set to 'wait for finish' mode.
</ul>
<p>These issues can be addressed by using the <i>unittest.TestCase.setUp()</i> and <i>unittest.TestCase.tearDown()</i> methods thus:</p>

<pre>
   def setUp(self):
    # Create a Qt application
    from core.CCP4Modules import QTAPPLICATION,PROCESSMANAGER
    self.app = QTAPPLICATION()
    # make all background jobs wait for completion
    PROCESSMANAGER().setWaitForFinished(10000)

   def tearDown(self):
    from core.CCP4Modules import PROCESSMANAGER
    PROCESSMANAGER().setWaitForFinished(-1)
</pre>

<p>To ensure portability of the tests you need to avoid any fixed filepaths in your tests. Please use a 'standard' temporary work directory:</p>
<pre>
   from core import CCP4Utils
   workDirectory = CCP4Utils.getTestTmpDir()
</pre>
<p>This will set <i>workDirectory</i> to your $HOME/ccp4i2_test. If this directory does not exist then it will be created. If you do not like this choice of directory then edit your local copy of CCP4Utils.</p>

<p>Typically the test code at the bottom of a pipeline module will look like this:<p>
<pre>
import unittest,os

class test_my_pipeline(unittest.TestCase):

   def setUp(self):
    from core import CCP4Modules
    self.app = CCP4Modules.QTAPPLICATION()
    # make all background jobs wait for completion
    # this is essential for unittest to work
    CCP4Modules.PROCESSMANAGER().setWaitForFinished(10000)

   def tearDown(self):
    from core import CCP4Modules
    CCP4Modules.PROCESSMANAGER().setWaitForFinished(-1)

   def test_1(self):
     from core import CCP4Modules, CCP4Utils
     import os

     workDirectory = os.path.join(CCP4Utils.getTestTmpDir(),'test1')
     if not os.path.exists(workDirectory): os.mkdir(workDirectory)

     self.wrapper = my_pipeline(parent=CCP4Modules.QTAPPLICATION(),name='test1',workDirectory=workDirectory)
     self.wrapper.container.loadDataFromXml(os.path.join(CCP4Utils.getCCP4I2Dir(),'pipelines','my_pipeline','test_data','test1.data.xml'))

     self.wrapper.setWaitForFinished(1000000)
     pid = self.wrapper.process()
     self.wrapper.setWaitForFinished(-1)
     if len(self.wrapper.errorReport)>0: print self.wrapper.errorReport.report()
     #test exit status correct
     exitStatus = CCP4Modules.PROCESSMANAGER().getJobData(pid,'exitStatus')
     self.assertEqual(exitStatus,0,'Process exit status non-zero: '+str(exitStatus))
     #test if output file created
     self.assertEqual(os.path.exists( str(self.wrapper.container.outputData.HKLOUT) ),1,'Failed to create copied pdb file '+ str(self.wrapper.container.outputData.HKLOUT))

def TESTSUITE():
  suite = unittest.TestLoader().loadTestsFromTestCase(test_my_pipeline)
  return suite

def testModule():
  suite = TESTSUITE()
  unittest.TextTestRunner(verbosity=2).run(suite)
</pre>
<p>The <i>unittest</i> sub-class <i>test_my_pipeline</i> has one or more methods called <i>test_*</i> which each perform one test. They do this by instantiating a plugin, loading suitable test data, calling the <i>process()</i> method to run the plugin and then testing that the plugin has run sucessfully. In this example the input data for <i>test_1</i> come from a 'PARAMS' xml file (called ..my_pipeline/test_data/test1.data.xml in the example code) that is loaded into the wrapper container by the <i>loadDataFromXml()</i> method. Typically such a file could be set up by using the GUI to run <i>my_pipeline</i> and then looking in the job directory for the <i>input_params.xml</i> file and copying it (along with any input data files) to the wrapper/pipeline <i>test_data</i> directory. The 'PARAMS' xml file will probably need to be editted to set the appropriate paths for input and output files. An input file will be in the CCP4I2 source code tree and should have <i>project</i> set to <i>CCP4I2</i> (which will find the the CCP4I2 root directory) and <i>relpath</i> set to the path to the <i>test_data</i> directory:
<pre>
    &lt;HKLIN&gt;
        &lt;project&gt;CCP4I2&lt;/project&gt;
        &lt;relPath&gt;pipelines/my_pipeline/test_data&lt;/relPath&gt;
        &lt;baseName&gt;whatsit.mtz&lt;/baseName&gt;
    &lt;HKLIN&gt;
</pre>
<p>And for an output files:</p>
<pre>
    &lt;HKLOUT&gt;
        &lt;project&gt;CCP4I2_TEST&lt;/project&gt;
        &lt;baseName&gt;whatsit.mtz&lt;/baseName&gt;
    &lt;/HKLOUT&gt;
</pre>
<p> CCP4I2_TEST is the 'temporary' directory returned by  CCP4Utils.getTestTmpDir().</p>
<p>The <i>unittest</i> documentation describes the test methods such as <i>assertEqual()</i> and typically a plugin test could check the return codes from the process and check that output files exist.</p>
<p>The sub-class of <i>unittest</i> (<i>test_my_pipeline</i> in the example above) does the real work but in the code above there are two extra functions:
</br/><b>TESTSUITE()</b> which should return the suite of tests and is used by the CCP4i2 overall test mechanism to find the test suite for that module. You could possibly have additional tests that are not returned by <i>TESTSUITE()</i> but those that are returned are part of CCP4i2 release tests.
</br/><b>testModule()</b> is a non-essential utility that can make running the module test from the Python prompt very quick:
<pre>
> import my_pipeline
> my_pipeline.testModule()
</pre>
</p>
<p>The script to run all the CCP4i2 module tests is <i>$CCP4I2/bin/runtest</i> which will search all of the <i>wrappers</i> and <i>pipeline</i> directories for <i>TESTSUITE()</i> functions and run them. The <i>runtest</i> script ignores scripts which specify their <i>TASKMODULE</i> as <i>demo</i> or <i>test</i> but reports any other module that does not have a <i>TESTSUITE()</i> function.

<a name="testing"><h3>Testing and Debugging Scripts</h3>
<p>If a job fails when run from the gui the key diagnostic should be presented in a report page; otherwise check in the <i>Project directory</i> view on the gui where you can see the job directory and should look at the <i>stout.txt</i>, <i>stderr.txt</i> and <i>diagnostic.xml</i> files. The <i>diagnostic.xml</i> file lists all Python exceptions from the script.</p>
<p>It is possible to run scripts and external programs from the console. After you have attempted to run a script from the gui there will be a job directory in the project directory (<i>project_path/CCP4_JOBS/job_nnn</i> where nnn is the job number listed in the gui) and this contains an input params file (<i>input_params.xml</i>). To rerun the script with these input parameters:
<pre>
> $CCP4I2_TOP/bin/runTask project_path/CCP4_JOBS/job_nnn/input_params.xml
</pre>
<p>Note that as this script is run it will update the database and progress will be shown if the gui is open.  Beware that rerunning jobs may have the potential for confusing the database so avoid doing this in important projects.</p>
<p>It is also possible to start the external process (i.e. running the program) from a Python console. The stdout from the script will list calls to the PROCESSMANAGER().startProcess() method that runs the wrapped program as an external process. The stdout output is formatted so that you can just cut-n-paste to rerun the external process from the ccp4i2 Python prompt, <i>ccp4i2/bin/pyi2</i>  (see <a href="./introduction.html#console">Console mode</a>). The command will look something like:
<pre>
>>> PROCESSMANAGER().startProcess("cbuccaneer", ["-stdin"], "/Users/lizp/Desktop/test_projects/t3/CCP4_JOBS/job_127/com.txt", "/Users/lizp/Desktop/test_projects/t3/CCP4_JOBS/job_127/log.txt")
</pre>
<p>The arguments to startProcess() are:</p>
<ul>
<li> <b>executable</b> - the executable to run </li>
<li> <b>args</b> - the command line arguments as a Python list of single words</li>
<li> <b>inputFile</b> - a command file</li>
<li> <b>logFile</b> - the output log file </li>
</ul>

<a name="buccaneer"><h3>Buccaneer - a realistic example wrapper</h3>
<p>See the <a href="../../wrappers/buccaneer/script/buccaneer.py">buccaneer script</a>. This re-implements three methods (in the order that they are called):
<br/><i>processInputFiles()</i> which convert the input data files into a form suitable for the wrapped program particularly using <i>makeHklin()</i> to convert mini-MTZs to a single input MTZ
<br/><i>makeCommandAndScript()</i> creates the command line and command file for the program
<br/><i>processOutputFiles()</i> converts the files output by the program to the standard forms of CCP4i2. It should also add appropriate default <i>CDataFile.annotation</i> (i.e. the label for a file that is seen in the gui) and appropriate <i>contentFlag</i> and <i>subType</i> attributes to the output mini-MTZ data objects.</p>
<p>Note that it should be unnecessary to re-implement the more generic and complex <i>process()</i> and <i>postProcess()</i> methods for wrappers. If you have a wrapper issue that can not be addressed with these three methods please talk to Liz. But pipelines do need the <i>process()</i> method re-implementing.</p>
<p>Also note that all of these methods must return either <i>CPluginScript.SUCCEEDED</i> or <i>CPluginScript.FAILED</i> which will determine whether the script will continue running or will abort.</p> 


<a name="miniMTZs"><h3>Handling Mini-MTZs</h3>
<p>Please read the user's introduction to mini-MTZs  <a href="../general/miniMTZs.html">here</a>. Each mini-MTZ contains 1 to 4 data columns to provide one consistent group of data and should never contain anything else. The columns in the mini-MTZ always have the same conventional names and types.</p>
<p>There is a CCP4XtalData.CMiniMtzDataFile sub-class of CCP4File.CDataFile to handle mini-MTZs. This is further subclassed to <i>CObsDataFile</i> (observed SFs or intensities),<i> CPhsDataFile</i> (phases represented as HL or phi/fom), <i>CMapCoeffsDataFile</i> (F/phi map coeficients) and <i>CFreeRDataFile</i>.<p>Two additional parameters have been added to the <i>CDataFile</i> class to keep track of the content of miniMTZs:
<ul>
<li><i>contentFlag</i> flags the representation and currently only applies to <i>CObsDataFile</i> and <i>CPhsDataFile</i> and the allowed values are listed in those classes (see below).</li>
<li><i>subType</i> (not yet fully implemented) flags the provenance of the data (e.g. observed or calculated) and will be used to guide appropriate use of the data.</li>
</ul>
<p>Note that other, non-MTZ files also have these parameters which might be put to use some time in the future. There are also two additional columns in the <i>Files</i> table of the database holding the same information.</p>

<p>These CMiniMtzDataFile classes also have several attributes that wrapper developers may need to access:
<br/><i>CONTENT_FLAG_xxxx</i> An allowed value for CMiniMtzDataFile.contentFlag parameter indicating a particular representation in the file
<br/><i>CONTENT_SIGNATURE_LIST</i> a list of the conventional column names
<br/><i>SUBTYPE_xxxx</i>An allowed value for CMiniMtzDataFile.subType parameter which has slightly different meaning for the different data types but generally indicates the provenance of the data.

<p>CCP4 intends to move to using mini-MTZs but as few programs currently support this way of working it is necessary for program wrappers to convert multiple mini-MTZs to and from a single MTZ that is the usual input to or output from a program.  This should be done in the wrappers re-implementation of <i>CPluginScript.processInputFiles()</i> and <i>CPluginScript.processOutputFiles()</i>. There are two methods to help with this conversion:
 <table border="1">
  <tr><th>CPluginScript method</th><th>Argument</th><th>Description</th></tr>
  <tr><td>makeHklin</td><td></td><td>Merge two or more mini-MTZs to make an 'HKLIN' file</td></tr>
     <tr><td></td><td>miniMtzsIn</td><td>A list of either: the names of <i>CMiniMtzDataFile</i> objects in the <i>container.inputParams</i> or a sub-list of the  <i>CMiniMtzDataFile</i> name and the required representation type (i.e. a <i>CONTENT_FLAG_xxxx</i> value).</td></tr>
     <tr><td></td><td>hklin</td><td>The basename of the output mtz - default 'hklin'</td></tr>
   <tr><td>splitHklout</td><td></td><td>Split an 'HKLOUT' file to multiple mini-MTZs</td></tr>
   <tr><td></td><td>miniMtzsOut</td><td>A list of the names of <i>CMiniMtzDataFile</i> objects in the <i>container.outputParams</i></td></tr>
   <tr><td></td><td>programColumnNames</td><td>A list of lists of column names in the ''HKLOUT' file specifying the columns to copy to the files in <i>miniMtzsOut</i> list</td></tr>
   <tr><td></td><td>inFile</td><td>Name of the 'HKLOUT' file - defaults to <i>workingDirectory/hklout.mtz</i></td></tr>
   <tr><td></td><td>logFile</td><td>Name of the log file for program runs - defaults to <i>workingDirectory/splitmtz.log</i></td></tr>
   <tr><td>splitHkloutList</td><td></td><td>Split a list of 'HKLOUT' files to mini-MTZs (see phaser_mr.py for example)</td></tr>
   <tr><td></td><td>miniMtzsOut</td><td>A list of the names of <i>CMiniMtzDataFile</i> objects in the <i>container.outputParams</i></td></tr>
   <tr><td></td><td>programColumnNames</td><td>A list of lists of column names in the ''HKLOUT' file specifying the columns to copy to the files in <i>miniMtzsOut</i> list</td></tr>
   <tr><td></td><td>outputBaseName</td><td>base name for output files to which a numerical index and filetype specification will be appended</td></tr>
   <tr><td></td><td>outputContentFlags</td><td>a list mapping to splitHkloutList with the content flag parameters to be set in the output mini-MTZs</td></tr>
   <tr><td></td><td>inFileList</td><td>A list of the 'HKLOUT' files to be processed to miniMTZs</i></td></tr>
   <tr><td></td><td>logFile</td><td>Name of the log file for program runs - defaults to <i>workingDirectory/splitmtz.log</i></td></tr>
 </table>



<a name="CPluginScript"/><h3><i>CPluginScript</i> Class Documentation</h3>
<p>The following class-wide attributes can be set in a <i>CPluginScript</i> sub-class. Examples of their use are given above. These parameters will usually be overruled by the same paramter if it appears in the gui definition <i>CTaskWidget</i> sub-class.  Note that it is also possible to have the <i>TASKTITLE</i> defined in the <i>def</i> file (actually called <i>PLUGINTITLE</i> as part of the file header) but this should not normally be used except possibly if there is more than one <i>def</i> file associated with the script and you need to distinguish them.</p>
<table border="1">
  <tr><td><b>CPluginScript Class Attributes</b></td><td><b>Description</b></td></tr>
  <tr><td>TASKNAME</td><td>The obligatory name of the script essential for cross-refererence to other files</td></tr>
  <tr><td>TASKVERSION</td><td>A version number for the script. Please give one!</td></tr>
  <tr><td>TASKMODULE</td><td>Refers to where the task should appear in the task menu, can be list of multiple modules see <a href="./task_guis.html#taskmenu">Task Menu</a></td></tr>
  <tr><td>TASKTITLE</td><td>The name for the task to appear in the GUI see <a href="./task_guis.html#taskmenu">Task Menu</a></td></tr>
  <tr><td>DESCRIPTION</td><td>More details to appear in the GUI see <a href="./task_guis.html#taskmenu">Task Menu</a></td></tr>
    <tr><td>MAINTAINER</td><td>Email address of first-call maintainer of this code</td></tr>

  <tr><td>TASKCOMMAND</td><td>The name of the executable that the script will run</td></tr>
  <tr><td>SUBTASKS</td><td>List of main sub-tasks that might be run by a pipeline script - currently used for <a href="./extras.html#bibliographic_references">bibliographic references</a></td></tr>
  <tr><td>COMTEMPLATE</td><td>A template for the program command file</td></tr>
  <tr><td>COMTEMPLATEFILE</td><td>The name of a file containing a program command template</td></tr>
  <tr><td>COMLINETEMPLATE</td><td>A template for the program command line</td></tr>
  <tr><td>INTERRUPTABLE</td><td>true/false can the script be interrupted?</td></tr>
  <tr><td>RESTARTABLE</td><td>true/false - can the script be restatred</td></tr>
  <tr><td>INTERRUPTLABEL</td><td>Text label to appear on button for interruptable sub-job</td></tr>
  <tr><td>DBOUTPUTDATA</td><td>A list of the output files to be saved to database - leave undefined for all to be saved</td></tr>
  <tr><td>ASYNCHRONOUS</td><td>Boolean flag if the script, or any of its children, run external processes asynchronously</td></tr>
  <tr><td>PERFORMANCECLASS</td><td>Name of class (in core/CCP4PerformanceData.py) that is used as the performance indicator for this plugin</td></tr>
  <tr><td>RUNEXTERNALPROCESS</td><td>Boolean flag (default True) indicating that an external program will be run</td></tr>
  <tr><td>CLONEABLE</td><td>Boolean flag  (default True) indicating if the task can be cloned</li>
</table>
<br/>
<br/>

<table border="1">
  <tr><td><b>CPluginScript Attributes</b></td><td><b>Description</b></td></tr>
  <tr><td>command</td><td>The name of 'executable' that the script will run.</td></tr>
  <tr><td>container</td><td>A <i>CContainer</i> that contains the parameters for a script. it is initialised by the DEF file in the plugin script directory</td></tr>
  <tr><td>workDirectory</td><td>The directory for files produced by the script</td></tr>
  <tr><td>errorReport</td><td>A <i>CErrorReport</i> containing a log of script run</td></tr>
  <tr><td>commandLine</td><td>A Python list of the words in the command line to the 'executable'. Should normally only be accessed using methods below.</td></tr>
  <tr><td>commandScript</td><td>A Python list of strings - one item for each line of a command file. Should normally only be accessed using methods below. </td></tr>
  <tr><td>async</td><td>Flag if external processes should be run asynchronously. Default False.</td></tr>
  <tr><td>timeout</td><td>Timeout period for an external process run in blocking mode.</td></tr>
  <tr><td>_db*</td><td>Parameters for interface to database and default directory and file names. Do NOT mess with these!</td></tr>
  <tr><td>runningProcessId</td><td>An i2-specific id for the last external process started by this plugin. This can be used to access info in the <i>PROCESSMANAGER</i></td></tr>
  <tr><td></td><td></td></tr>
 </table>
<br/>
<br/>
 <table border="1">
  <tr><th>CPluginScript method</th><th>Argument</th><th>Description</th></tr>
  <tr><td>__init__</td><td></td><td></td></tr>
     <tr><td></td><td>parent</td><td>A parent class. Use <i>CCP4Module.QTAPPLICATION()</i> if nothing else is appropriate.</td></tr>
     <tr><td></td><td>name</td><td>A unique name for the instance of the class. If <i>makePluginObject()</i> is used to instantiate object then it will create a name dependent on the project and job id.</td></tr>
     <tr><td></td><td>workDirectory</td><td>A directory for 'temporary' files.</td></tr>
  <tr><td>makePluginObject</td><td colspan="2">Create an instance of a CPluginScript sub-class - should be used rather than instantiating directly</td></tr>
     <tr><td></td><td>pluginName</td><td>Name of wrapper/pipeline CPluginScript sub-class</td></tr>
     <tr><td></td><td>reportToDatabase</td><td>Report the new plugin instance (i.e. job) to the database - default <i>True</i></td></tr>
  <tr><td>loadContentsFromXml</td><td colspan="2">Set the contents of the container from the DEF file in the plugin directory.</td></tr>
  <tr><td>checkInputData</td><td colspan="2">The base class implementation checks that all files specified in the <i>container.inputData</i> actually exist and returns a list of non-existant file (this is wrong - it should return a CErrorReport) </td></tr>
  <tr><td>checkOutputData</td><td colspan="2">Provide output file names if missing</td></tr>
     <tr><td></td><td>container</td><td><i>CContainer</i> to check - default <i>None</i> will check <i>self.container</i></td></tr>
  <tr><td>appendErrorReport</td><td colspan="2">Append an error description to the overall plugin error report.</td></tr>
     <tr><td/><td>code</td><td>An error code number unique for the class - must be key in the class ERROR_CODES dictionary</td></tr>
     <tr><td/><td>details</td><td>A Python string containing further information (e.g. name of file that you could not read). Default <i>None</i></td></tr>
     <tr><td/><td>name</td><td>A Python string with an identifier for the data object. <i>CData.objectPath()</i> gives suitable value for this.Default <i>None</i></td></tr>
     <tr><td/><td>cls</td><td>The class reporting the error. Default <i>None</i> will be interpreted as current class.</tr>
  <tr><td>extendErrorReport</td><td colspan="2">Append errors from another <i>CErrorReport</i> object to this object</td></tr>
     <tr><td/><td>other</td><td>A <i>CErrorReport</i> or <i>CException</i></td></tr>
  <tr><td>appendCommandLine</td><td colspan="2">Append words to the command line to run an 'executable'</td></tr>
     <tr><td></td><td>*args</td><td>Arguments can be Python strings, <i>CData</i> object, or a list (Python list or <i>CList</i>) of these.</td></tr>
  <tr><td>appendCommandScript</td><td colspan="2">Add a line to the command script</td></tr>
     <tr><td></td><td>text</td><td>A Python string or object with __str__() method or a list (Python or CList) of these.</td></tr>
  <tr><td>writeCommandFile</td><td colspan="2">Write text from the comand script to a file (the name is determined automatically).</td></tr>
  <tr><td>makeFileName</td><td colspan="2">Generate an appropriate file name based on the work directory and unique plugin name.</td></tr>
    <tr><td></td><td>format</td><td>The file format - either 'COM','LOG','PARAMS' or 'PRORAMXML'</td></tr>
    <tr><td></td><td>ext</td><td>Optional file extension - overrides the extension implied by the format</td></tr>
    <tr><td></td><td>baseName</td><td>Optional base filename that overrides the plugin name.</td></tr>
  <tr><td>process</td><td colspan="2">Default method to run an executable. Runs <i>checkInputData</i>, <i>makeCommandAndScript</i> and <i>startProcess</i></td></tr>
  <tr><td>makeCommandAndScript</td><td colspan="2">Creates command line and script from COMTEMPLATE or COMTEMPLATEFILE and COMLINETEMPLATE. Or may be reimplemented in sub-classes</td></tr>
  <tr><td>startProcess</td><td colspan="2"> Call <i>PROCESSMANAGER().startProcess()</i> to start external process. Returns job status CPluginScript.SUCCEEDED or CPluginScript.FAILED.</td></tr>
     <tr><td></td><td>command</td><td>The external 'executable'. </tr>
     <tr><td></td><td>reportStatus</td><td>Boolean, default True. If True startProcess calls reportStatus when complete.</tr>
  <tr><td>postProcess</td><td colspan="2">Called after an external process started by <i>startProcess</i> finishes.Can be reimplemented but must call <i>reportStatus()</i></td></tr>
     <tr><td></td><td>processId</td><td></td></tr>
     <tr><td></td><td>data</td><td></td></tr>
  <tr><td>postProcessWrapper</td><td colspan="2">Can be called at end of pipeline script instead of <i>postProcess</i> to clean up after last wrapper plugin</td></tr>
     <tr><td></td><td>finishStatus</td><td>Finish status of last wrapper - <i>CPluginScript.SUCCEEDED</i> or <i>CPluginScript.FAILED</i>.</td></tr>
  <tr><td>reportStatus</td><td colspan="2">Reports completion to database, writes PARAMS file, emits a 'finished' signal with an job status.</td></tr>
       <tr><td></td><td>finishStatus</td><td>Finish status of job - <i>CPluginScript.SUCCEEDED</i> or <i>CPluginScript.FAILED</i>.</td></tr> 
  <tr><td>postProcessCheck</td><td colspan="2">Query the process manager to find out if the external job succeeded. Returns  <i>CPluginScript.FAILED</i> or <i>CPluginScript.SUCCEEDED</i></td></tr>
     <tr><td></td><td>processId</td><td>The process id - as returned by <i>startProcess()</i></td></tr>
  <tr><td>logFileText</td><td colspan="2">Return the text of a log file created by the external process.</td></tr>
  <tr><td>updateJobStatus</td><td colspan="2">Report job status to database - provide <i>status</i> or <i>finishStatus</i> </td></tr>
  <tr><td></td><td>status</td><td>A CCP4DbApi JOBSTATUS_*</td></tr>
  <tr><td></td><td>finishStatus</td><td><i>CPluginScript.SUCCEEDED</i> or <i>CPluginScript.FAILED</i></td></tr>
   <tr><td>saveParams</td><td colspan="2">Save the content of self.container to a file <i>baseName.params.xml</i></td></tr>
   <tr><td>getProcessId</td><td colspan="2">Return the processId which can be used to query PROCESSMANAGER()getJobData()</td></tr>
    <tr><td>joinMtz</td><td colspan="2">Join multiple MTZs into one MTZ</td></tr>
     <tr><td></td><td>outFile</td><td>Full path name of the output file</td></tr>
    <tr><td></td><td>inFiles</td><td>A list, each element is a list of two elements: the full path name of a input file and a text string of comma-separated column names.</td></tr>
    <tr><td>splitMtz</td><td colspan="2">Split one MTZ into multiple MTZs</td></tr>
     <tr><td></td><td>inFile</td><td>Full path name of the input file</td></tr>
     <tr><td></td><td>outFiles</td><td>A list, each element is a list of three elements: the full path name of a output file, the input columns and the corresponding output columns. Thr input and output columns are a text string of comma-separated column names.</td></tr>
</table>



<a name="moving data"/><h3>Moving Data Between Plugins</h3>
<p>Data is held in a <i>CContainer</i> which is described <a href="./data_classes.html#containers">here</a>. Pipeline scripts usually need to copy data from their own container to to wrapper containers or between wrapper containers. Single items of data can be copied simply by equivalencing:
<pre>
      self.pdbset.container.inputData.XYZIN = self.container.inputData.XYZIN
</pre>
<p>If you need to copy more data between plugins then use <i>CContainer.copyData()</i> which copies data into the container. There are two arguments:
<br/>&nbsp;&nbsp;&nbsp;<i>otherContainer</i> - container to copy from
<br/>&nbsp;&nbsp;&nbsp;<i>dataList</i> - list of items to copy. If no list is provided it will copy all items with the same name (use with care!).
<br/>For example:</p>
<pre>
   self.pdbset.container.inputData.copyData(self.container.inputData,['XYZIN'])
</pre>

<a name="running processes"/><h3>Asynchronous Pipelines</h3>
<p>The <i>CPluginScript</i> method uses <i>PROCESSMAMANGER().startProcess()</i> to start the programs in a separate process.  By default external processes are run in blocking mode i.e. the script does not continue until after the external program has completed. This is fine for single wrappers or pipelines performing a series of consecutive steps but for some pipelines you may want to have several program runs start concurrently and then process the result for each run as it completes. There is a trivial example of how to do this in the pipeline <a href="../../pipelines/demo_multi_mtzdump/script/demo_multi_mtzdump.py/">demo_multi_mtzdump</a> that runs multiple instances of the <i>mtzdump</i> program that extracts data from an MTZ file. The <a href="../../wrappers/mtzdump/script/mtzdump.py/">mtzdump wrapper</a> is a simple wrapper requiring no specific features to support this functionality. The <i>demo_multi_mtzdump.process()</i> method makes a list of mtz files and then creates one instance of the <i>mtzdump</i> wrapper for each file using the usual <i>makePluginObject()</i> method. In this example the call to <i>makePluginObject()</i> has the <i>reportToDatabase</i> argument set False to prevent the individual tasks being saved to the database but this is not at all a requirement for plugins that are run asynchronously. The name of the input mtz is set in <i>mtzdump</I> object and then the code that is specific for asynchronous running:</p>
<pre>
        # Set to run asynchronously and set a callback
        mtzdump.async = True
        mtzdump.setFinishHandler(self.handleDone)
        #Start process
        rv = mtzdump.process()
        #The mtzdump instance must be saved to keep it in scope and everything else can be got from that.
        self.subProcessList.append(mtzdump)
</pre>
<p>The  <i>mtzdump.async</i> parameter is set <i>True</i> and callback is set to <i>self.handleDone</i> a method defined later in the script. The <i>mtzdump</i> is started by calling <i>mtzdump.process()</i> and the mtzdump object is saved to a list; this is essential to ensure it does not go out of scope when the <i>demo_multi_mtzdump.process()</i> method returns. The <i>handleDone()</i> method is called as each mtzdump process finishes and is passed the <i>jobId</i> and a <i>processId</i> from the completed run. The <i>jobId</i> will be None if the script is run in a context without the CCP4i2 database or if (as here) the  <i>reportToDatabase</i> is False. So it is best, as in this example, to use the pid to find which mtzdump instances has finished:

<pre>
      # Get the exit status and if successful get the CELL from the outputData
      if self.postProcessCheck(pid) == CPluginScript.SUCCEEDED:
        for p in self.subProcessList:
          if p.processId == pid:
            print p.container.inputData.HKLIN,p.container.outputData.CELL
            self.subProcessList.remove(p)
</pre>
<p>In this trivial example a result is printed out and the finished mtzdump instance is removed from the list of sub-processes. It is also very important that this callback method tests for when all sub-processes are finished and calls <i>CPluginScript.reportStatus()</i> with a suitable status flag:</p>
<pre>
      if len(self.subProcessList)==0:
        self.reportStatus(CPluginScript.SUCCEEDED)

</pre>

<p>One other essential feature is that the <i>demo_multi_mtzdump</i> class has an attribute  <i>ASYNCHRONOUS</i> set to True at the top of the class definition:</p>
<pre>
  class demo_multi_mtzdump(CPluginScript):
    TASKTITLE = 'Demo multi MTZ dump'
    TASKNAME = 'demo_multi_mtzdump'
    ASYNCHRONOUS = True
</pre>
<p>This is a flag to the infrastructure running the task to ensure that the necessary event loops and threads are set up before creating an instance of the class.</p>

<a name="connectSignal"/><h3>Connecting a pipeline with connectSignal()</h3>
<p>An alternative approach to running pipelines asynchronously is after creating the first subtask but before calling its <i>process()</i> method, use <i>connectSignal()</i> to connect the 'finished' signal from that first subtask to a target function that will start the second subtask.  This is shown below in an extract from <i>aimless_pipe.py</i> where the first <i>pointless</i> plugin is created and then a <i>connectSignal()</i> call ensures that the 'finish' signal will invoke <i>process_aimless()</i> method. The <i>process_aimless()</i> method first checks the finish status of the <i>pointless</i> subtask and then runs <i>aimless</i> and calls <i>connectSignal()</i> to get <i> process_cycle_ctruncate()</i> called when the <i>aimless</i> plugin finishes .. and so on.</p>
<p>One issue with using <i>connectSignal()</i> is that the target function can crash without any exception being passed up to a calling function so there is no evidence of what happened and no call to <i>reportStatus()</i> to cleanup and ensure that the job is recognised to have failed. So for the user the job appears to be still running.  The way to handle this is to wrap all of the functionality in the target method in a <i>try..except</i> statement with the <i>except</i> body calling <i>appendErrorReport()</i> and <i>self.reportStatus(CPluginScript.FAILED)</i>.  This gets the exception shown in the job's diagnostic and ensures that the pipeline is correctly reported as failed. The <i>CPluginScript</i> error code 39 is a generic 'Unknown error'.  It would be better to have several <i>try..except</i> statements and to append more informative <i>CException</i> (ie ccp4i2 exception) to the pipeline error log using <i>appendErrorReport()</i>.</p>
<pre>
  def process(self):
      print "### Starting aimless pipeline ###"
      ...
      self.process_pointless()

    def process_pointless(self):
      print "### Running pointless ###"
      ...
      self.pointless = self.makePluginObject('pointless')
      ...
      self.connectSignal(self.pointless,'finished',self.process_aimless)
      self.pointless.process()

    def process_aimless(self,status):
      if status.get('finishStatus') == CPluginScript.FAILED:
         self.reportStatus(status)
         return
      try:
        print "### Running aimless ###"
        crash #Test the fail mechanism

        # Run aimless to edit model
        self.aimless = self.makePluginObject('aimless')
        ...
        self.connectSignal(self.aimless,'finished',self.process_cycle_ctruncate)
        self.aimless.process()
      except Exception as e:
        print e
        self.appendErrorReport(CPluginScript,39,str(e))
        self.reportStatus(CPluginScript.FAILED)
</pre>
<!--
<h3>Notes on demo_multi_mtzdump example</h3>
<p>In this example the pipeline finds all of the MTZ files in <i>test_data</i> directories and runs <i>mtzdump</i> once for each file to extract the cell. When all of the jobs have finished the file names and cells are listed to the terminal. In principle the different runs of mtzdump are asynchronous (though see discussion later). In future, with a more sophisticated process manager that can farm jobs to other harware resources, something like this example could run multiple large jobs in parallel.</p>
<p>The demo_multi_mtzdump.process() method instantiates an mtzdump for each mtz file and keeps a list of them as <i>self.mtzdump_processes</i>
<pre>
     self.mtzdump_processes.append( mtzdump.mtzdump(parent=self,name='test_mtzdump',inputData=inputData))
</pre>
The next step of connecting the mtzdump finish signal to the <i>demo_multi_mtzdump.process_1()</i> method has a little trick to ensure that the <i>process_1()</i> method knows which mtzdump process has finished.
<pre>
     from functools import partial
     ...
     self.connectSignal(self.mtzdump_processes[-1],'finished',partial(self.process_1,iMtzdump))
</pre>
The <i>functools.partial</i> method adds the argument <i>iMtzdump</i> (a counter for the mtzdump jobs) to the call to <i>process_1()</i> so that method now expects both the counter and a status and handles the result data from mtzdump appropriately. <i>process_1()</i> then tests if it has results for all MTZ files and, if it has, it writes out the results.</p>

<p>The usual unittest setup calls <i>PROCESSMANAGER().setWaitForFinished(10000)</i> to get the process to return only after the external job has finished. This is necessary to prevent the unittest finishing before the external process has finished. But this spoils the demo of running jobs asynchronously.  To run the jobs asynchronously we need to have an event loop.  The easiest way to do this is to use the Qt graphical application event loop so that to run the test looks like this:
<pre>
prompt> python
....
....
>>>app = startGraphics()
>>>import demo_multi_mtzdump; demo_multi_mtzdump.runAllTests()
</pre>
You will need to Ctrl-d to exit.
</p>
-->
<a name="internal"/><h3>A 'Wrapper' that does not run an External Process</h3>
<p>It is possible that a wrapper might do the processing itself without running another program in another external process.  In this case the developer should reimplement the <i>startProcess()</i> method to do the necessary processing and should set the class parameter <i>RUNEXTERNALPROCESS</i> to <i>False</i>. An example of a script which does this is <a href="../../wrappers/mergeMtz/script/mergeMtz.py"><i>mergeMtz</i></a> which just calls the utility <i>CPluginScript.joinMtz()</i> to perform its functionality. Note that <i>startProcess()</i> should return <i>CPluginScipt.SUCCEEDED</i> or <i>CPluginScipt.FAILED</i>. </p>

<pre>
class mergeMtz(CPluginScript):

    TASKTITLE = 'Merge experimental data objects to MTZ'     # A short title for gui menu
    TASKNAME = 'mergeMtz'                                    # Task name - should be same as class name
    RUNEXTERNALPROCESS = False                               # There is no external process

    def startProcess(self,command,**kw):

      '''
          Some data preparation
      '''
          
      status = self.joinMtz(self.container.outputData.HKLOUT.fullPath.__str__(),inFiles)
      return status

</pre>


<a name="interrupt-restart"/><h3>Interrupting and restarting processes</h3>
<p>For an example see <i>pipelines/buccaneer_build_refine/scripts/buccaneer_build_refine.py</i> which will stop at the end of a buccaneer-refmac cycle if it receives an interrupt signal. The pipeline can test if there is an interrupt signal at a suitable break point by calling <i>CPluginScript.testForInterrupt()</i> which will return True if an interrupt request has been made. At this point the script should:
<il>
<li>do whatever to terminate the script cleanly with meaningful results</li>
<li>if the script supports restart it should save any necessary parameters - e.g. buccaneer_build_refine has an extra <i>interruptStatus</i> container in the def file to hold these parameters.</li>
<li>call <i>self.reportStatus(CPluginScript.INTERRUPTED)</i> to register with the database that the job is interrupted</li>
<li> <i>return</i> from the script</li>
</il>
<p> If the script supports restart then the start of the script should check the saved parameters (e.g. in the <i>interruptStatus</i> container and set the starting parameters appropriately. To notify the system that a script supports interrupt or restart the class attributes <i>INTERRUPTABLE</i> and <i>RESTARTABLE</i> should be set to True.</p>
<p>There is an alternative mechanism to support stopping a sub-job in a pipeline so that the pipeline can continue.  This is best seen in the CRANK2 pipeline. The interruptable task should have the task attribute INTERRUPTLABEL set to a text string that is a label to appear on button underneath the task report. If the user clicks this button then there is a signal that can be checked for with the  <i>CPluginScript.testForInterrupt()</i> method as described above. The pipeline should have a mechanism to continue to the next step when it gets this signal.  To make this tool usable the job report should be showing the progress of the sub-job so the user can make a sensible decision when to interrupt it and the subsequent report should probably contain a note that the job was interrupted.</p>
<p>The sub-job interrupt was implemented for the benefit of CRANK2 and has some obvious limitations - if a task has INTERRUPTLABEL attribute then it applies in all pipelines that run the task - subclassing the task class could be used to get around this. The system currently only suuports interrupting the immediate children of a pipeline task.</p>

<a name="performance_indicators"/><h3>Performance Indicators</h3>
<p>A performance indicator is one or more simple parameters that give an indication of the effectiveness of a job - for example R-factors and free R-factors can be performance indicators for refinement.  CCP4i2's use of performance indicators is currently in development but the basic approach is that a plugin script saves the key parameters in the <i>outputData</i> section of the <i>def</i> file and they will be picked up from here by the CCP4i2 system and saved to the database. These parameters are then displayed in the project window. In future the parameters stored in the database might help to guide automated structure solution.</p>

<p>The file <a href="../../core/CCP4PerformanceData.py"><i>core/CCP4PerformanceData.py</i></a> contains the definitions of performance indicator classes that are sub-classed from <i>CPerformanceIndicator</i>.  It is expected that there should be one performance indicator class for each stage in structure solution so tasks that perform a similar function should use the same performance indicator class (the classes will provide interconversion of different representations and whatever else is necessary to make this work).  The currently defined classes hold several parameters that are all either floats or strings and the mechanism to save data to the database currently only handles floats (or integers converted to floats) or strings (255 character limit) but this convention could be changed if necessary. The parameters in each class are up for discussion.</p>
<p>To use a performance indicator a plugin class should set the class variable PERFORMANCECLASS to the name of the performance class used (this is there to help in efficiently generating the display in the project window). In the <i>def</i> file <i>outputData</i> section a variable (usually called <i>PERFORMANCEINDICATOR</i> but that is optional) is declared with the appropriate class. At the end of the process, the plugin script should set the parameters in the performnce indicator object.  To see an example of this look for 'PERFORMANCE' in <a href="../../pipelines/bucref/script/buccaneer_build_refine.def.xml">../../pipelines/bucref/script/buccaneer_build_refine.def.xml</a> and  <a href="../../pipelines/bucref/script/buccaneer_build_refine.py">../../pipelines/bucref/script/buccaneer_build_refine.py</a>


<a name="project_defaults"><h3>Project Defaults</h3>
<p>This is a mechanism to set some parameter(s) for a given task for every time that task is run within a project. Typically it might be used to control restraints in Refmac runs when these need customising for the particular coordinate data in the project. A task that wants to set some default parameters (for subsequent runs of the same task or for another task) creates a fragment of the <i>params</i> file for the task containing only the required parameters and saves this file to the <i>CCP4_PROJECT_FILES</i> sub-directory of the project directory. When the task plugin is created the appropriate <i>default params</i> file is automatically loaded.</p>
<p>The implementation of this feature is under development but presently there are two <i>CPluginScript</i> methods to enable a developer to create or edit a <i>default params</i> file. For example to set the <i>WEIGHT</i> parameter for a Refmac wrapper.</p>

<pre>
   defaultsContainer = self.getProjectDefaultParameters(taskName='refmac_martin',paramsList=['WEIGHT'])
   if defaultsContainer.controlParameters.WEIGHT != 2.0:
     defaultsContainer.controlParameters.WEIGHT = 2.0
     self.saveProjectDefaultParameters(defaultsContainer)
</pre>
<p>Here <i>CPluginScript.getProjectDefaultParameters()</i> has been called with the name of a task and a list of the parameters that will be set.  This method returns a 'top-level' container with the usual sub-containers (<i>inputData</i>,<i>controlParameters</i> and <i>outputData</i>) but only the listed parameters.  Except if there is already a <i>default params</i> file for this task then the contents of that file plus the listed parameters are returned. You should check that the required defaults have not already being set (this is to avoid unnecessary extra versions of the defaults file), set the required defaults  and then save the edited defaults using <i>CPluginScript.saveProjectDefaultParameters()</i>. Note that the defaults file is saved with the header containing the jobId and jobNumber of the job that created it and the <i>default params</i> files are versioned with file names of the form
<br\> <i>CCP4_PROJECT_FILES/refmac_martin_001.params.xml</i></p>
<p>The defaults file is read and loaded by <i>CPluginScript.loadProjectDefaults()</i> called from <i>CPluginScript.process()</i> (currently commented out - Dec 2014).</p>

<p>There are several issues with this mechanism - please discuss with Liz before using it.</p>


<a name="non-i2"><h3>Incorporating non-CCP4i2 pipelines</h3>
<p>It is possible to get a pipeline not written with CCP4I2 <i>CPluginScript</i> to appear in the i2 database and GUI. This could avoid writing wrappers for every program called by the pipeline but does require following some I2 conventions:</p>
<il>
<li>The pipeline 'top' script must be a CPluginScript</li>
<li>The pipeline must place its output files (data file, log files) in the specified directory ( CPluginScript.workDirectory)</li>
<li>Each sub-process that you want to be visible to i2 must have output and log files placed in the i2 specified directory</li>
<li>For each sub-process a dummy <i>CPluginScript</i> must by created and its data container loaded with info on input and output data.</li>
<il>
<p>The <i>dummy</i> pipeline (<i>dumMee</i> in the <i>test</i> folder of the GUI) has a script <i>$CCP4I2_TOP/pipelines/dummy/script/dummy.py</i> that demonstates how to do this.</p>
<p>The CRANK2 pipeline is an example of this.</p>

<a name="testing"><h3>Testing and Debugging Scripts</h3>
<!--<i>ccp4Python</i> command prompt (see <a href="./introduction.html#console">Console mode</a>).-->
<p>It is possible to run scripts and external programs from the console.
After you have attempted to run a script from the gui there will be a job directory in the project directory (<i>project_path/CCP4_JOBS/job_nnn</i> where nnn is the job number listed in the gui) and this contains an input params file (<i>input_params.xml</i>). To rerun the script with these input parameters:
<pre>
> $CCP4I2_TOP/bin/Python $CCP4I2_TOP/bin/runTask.py >project_path/CCP4_JOBS/job_nnn/input_params.xml
</pre>

</p>

<a name="exporting_task"><h3>Exporting a task as a compressed file</h3>
<p>This is a mechanism to create a compressed file (currently a zip) to make available to a limited number of users as an alternative to checking code into the normal CCP4i2 repository for general distribution.  The code to export must be a sub-directory of the <i>pipelines</i> directory and should be cleaned of <i>.pyc</i> and other superfluous files. The <i>Export task</i> option is on the <i>Developer tools</i> sub-menu of the <i>Utilities</i> menu.  You will be asked to choose the directory to export and the compressed file will be placed in the <i>pipelines</i> directory.  The user can import the task via the <i>Import task</i> option on the <i>Utitlities</i> menu.</p>

<a name="export_file_menu"><h3>Exporting files from a job</h3>
<p>In the project window job list the job context menu can include an option to export files from the job. This is likely to be particularly useful for exporting 'monster' MTZ files for use outside CCP4i2 but it could work for any file that either exists in the job directory or sub-directory or can be created from the data there.  The task script module should provide two functions (note functions not methods of the CPluginScript class):
<br/><br/><b>exportJobFileMenu( jobId )</b> - is called when the user opens the job context menu and should return details of items to appear on an 'Export' menu. The function is passed the jobId of the job chosen by the user and should return a list where each item is a sub-list of three strings:
<br>&nbsp;&nbsp;&nbsp;&nbsp;an identifier that will be <i>mode</i> input to <i>exportJobFile()</i>
<br>&nbsp;&nbsp;&nbsp;&nbsp;the text string that will appear on the <i>Export</i> sub-menu - should inform the user exactly what will be exported
<br>&nbsp;&nbsp;&nbsp;&nbsp;the mime type of the exported file (see CCP4CustomMimeTypes) - used by the file selection dialog for file extensions etc.
<br/><br/><b>exportJobFile( jobId , mode)</b> - is called when the user selects one of the options from the <i>Export</i> sub-menu. The function is passed the jobId of the selected job and the identifier from the sub-menu item. The function should return the filename of the file to export - it may need to create a temporary file.  There is an example of this in the aimless_pipe script. A code fragment that might be useful in this context:<p>
<pre>
    from core import CCP4Modules
    childJobs =CCP4Modules.PROJECTSMANAGER().db().getChildJobs(jobId=jobId,details=True,decendents=False)
    for jobNo,jobId,taskName  in childJobs:
      if taskName == 'ctruncate':
        f = os.path.join( CCP4Modules.PROJECTSMANAGER().jobDirectory(jobId=jobId,create=False),'HKLOUT.mtz')
        if os.path.exists(f): return f
</pre>
<p>Here the <i>CDbApi.getChildJobs()</i> returns a list of the subJobs for the <i>jobId</i> with the job number, jobId and taskname for each sub-job returned. The <i>CProjectsMaanger.jobDirectory()</i>  returns the job directory for any job or sub-job.</p>
<p>A likely requirement to create suitable export files is merging two or more MTZs.  The usual CCP4i2 approach using <i>cmtzjoin</i> expects to work with column groups corresponding to i2 data objects and may not work for the 'old style' MTZs that are being exported. There is a simple interface to the CAD program via <i>CMtzDataFile.runCad()</i>. This has arguments: 
    <br/>&nbsp;&nbsp;<i>hklout</i> - output file name
    <br/>&nbsp;&nbsp;<i>hklinList</i> - list of mtz to be merged with the file referenced by <i>CMtzDataFile</i>
    <br/>&nbsp;&nbsp;<i>comLines</i> - list of strings to go into command file (END not necessary)
<br/>If <i>comLines</i> is zero length then the compulsary LABIN input will be set to 'ALL' for all input files. If you require anything other than all the files merging you should set <i>comLines</i> to the necessary CAD command lines. This return  hklout(str),err(CErrorReport).</p>
<p>The <i>hklout</i> should be set to something like 'export.mtz' in the job directory and <i>runCad()</i> will create this file and <i>export_cad.com</i> and <i>export_cad.log</i> in the job directory.</p>
<p>Example:</p>
<pre>
def exportJobFile(jobId=None,mode=None):
    import os
    from core import CCP4Modules
    from core import CCP4XtalData

    jobDir = CCP4Modules.PROJECTSMANAGER().jobDirectory(jobId=jobId,create=False)
    exportFile = os.path.join(jobDir,'exportMtz.mtz')
    if os.path.exists(exportFile): return exportFile

    ...
    
    m = CCP4XtalData.CMtzDataFile(truncateOut)
    #print m.runCad.__doc__   #Print out docs for the function
    outfile,err = m.runCad(exportFile,[ freerflagOut ] )
    return   outfile
</pre>


<a name="temp"><h3>Temporary files and file cleanup</h3>
<p>Considerations:
<br/>Ideally wrappers and task guis should put intermediate files in the appropriate job directory so they can be found and (potentially) bundled in when a job or project is exported. Or found and deleted.
<br/>There is a need to limit the size of job and project directories since users may want to export them and compressing and moving large files is slow.
<br/>Many programs create large intermediate files. Many pipelines have little used intermediate data files.


<p>In order to limit disk usage and user information overload some 'scratch files' or little used files are deleted. At the end of a job run the core system automatically applies a file cleanup and there are user interface options to cleanup files from an individual job or whole project.  To support this the core system keeps a list of files that can be deleted and individual tasks should have a list of files specific to the task.  The <i>CCP4ProjectsManager.CPurgeProject</i> class handles this and the parameters shown below come from that class. The multi-step process of assigning files to a catagory and then deleting certain catagories in a given context allows for user customisation and the inevitable change of requirements.<p>

<p>The deletable files are assigned to a catagory:
<pre>
  PURGECODES = { 1 : 'Scratch file',
                 2 : 'Scratch file potentially useful diagnotic',
                 3 : 'Diagnostic file',
                 4 : 'File redundant after report created',
                 5 : 'Intermediate data file',
                 6 : 'Redundant on project completion',
                 7 : 'Large file that could be deleted',
                 0 : 'Retained file - used to override default' }
</pre>
<p>In any context the catagories of file that can be deleted are specified (e.g. [1,2] on completion of a job). The <i>CPurgeProject</i> class also has a default list of files and purge catagories that specify files created by many or all tasks.  This currently is:

<pre>
  SEARCHLIST = [ [ '*-coordinates_*.*', 1 ],
                 [ 'report.previous_*.html' , 1 ],
                 [ 'report_tmp.previous_*.html' , 1 ],
                 [ 'params.previous_*.xml' , 1 ],
                 [ 'diagnostic.previous_*.xml' , 1 ],
                 [ 'hklin.mtz' , 1 ],
                 [ 'hklout.mtz', 1 ],
                 [ '*mtzsplit.log', 2 ],
                 [ 'log_mtz*.txt', 2 ],
                 [ 'sftools', 2 ],
                 [ 'ctruncate', 2 ],
                 [ 'scratch', 2 ],
                 [ 'stderr.txt' , 3],
                 [ 'stdout.txt' , 3],
                 [ 'diagnostic.xml' , 3],
                 [ 'report_tmp.html' , 4 ],
                 [ 'program.xml' , 4 ],
                 [ 'XMLOUT.xml' , 4 ],
                 [ 'log.txt', 4 ],
                 [ '*.scene.xml' , 6 ],
                 [ '*observed_data_as*', 6 ],
                 [ '*phases_as*', 6 ],
                 [ '*%*/report.html', 6 ],
                 [ '*%*/tables_as_csv_files', 6 ],
                 [ '*%*/tables_as_xml_files', 6 ],
                 [ '*%*/params.xml', 6 ],
                 [ 'com.txt', 6 ] ]
</pre>
<p>So, for example, <i>hklin.mtz</i> is catagory 1, a scratch file that is liable to be deleted in many context. But many tasks have either addition files suitable for deletion or perhaps some that require saving despite appearing on the above list. Particularly pipelines might have sub-job files suitable for deletion. The task-specific files should be listed as an attribute of the plugin class - for example for the <i>import_merged</i> task:
<pre>
    PURGESEARCHLIST = [ [ 'HKLIN*.mtz' , 1 ],
                        ['aimless_pipe%*/HKLOUT*.mtz', 1]
                       ]
</pre>
<p><i>PURGESEARCHLIST</i> is a list of filename and purge catagory pairs. Here intermediate input mtz files and the output from <i>aimless_pipe</i> (run just for the analysis) are catagorised at scratch files (catagory 1). Note that '*' can be used as a wildcard in filenames and that files in sub-jobs are specified by <i>taskname</i>%<i>subjob_number</i>/<i>filename</i>. The <i>taskname</i> or <i>subjob_number</i> can have '*' as wildcard. The sub-jobs can be nested. A more complex example is for <i>buccaneer_build_refine_mr</i>:</p>
<pre>
    PURGESEARCHLIST = [ [ 'buccaneer_mr%*/XYZOUT.*' , 5 , 'XYZOUT' ],
                      [ 'refmac%*/ABCDOUT.mtz', 5, 'ABCDOUT' ],
                      [ 'refmac%*/FPHIOUT.mtz', 5, 'FPHIOUT' ],
                      [ 'refmac%*/DIFFPHIOUT.mtz', 5, 'DIFFPHIOUT' ]
     ....
                      [ 'prosmart_refmac%*/refmac%*/XYZOUT.pdb', 5, 'XYZOUT' ],
                      [ 'prosmart_refmac%*/refmac%*/COOTSCRIPTOUT.scm', 5, 'COOTSCRIPTOUT' ] ]
</pre>
<p>Here the files being catagorised are the intermediate sub-job data files from <i>buccaneer_mr</i> and <i>refmac</i> subtasks which by default the sub-tasks record in the project database. When these files are deleted they must also be removed from the database and the list above also gives the sub-job parameter name for each file so it can be found in the database and removed.</p>
<p>The purge mechanism builds a search list for a job by first creating a search list for sub-jobs composed of the program-wide default list overridden by the specific purge list for the sub-job task and then overidden by the parent task purge list. Then, for all items on the search list in the right catagories for the context, the mechanism looks for files matching the filename and deletes them.</p>


<h3>Appendix</h3>
<a name="parents"><h5>Parents</h5>
<p>For Qt signals to work <i>CPluginScript</i> is sub-classed from a <i>QObject</i>. All <i>QObject</i>s must have a parent which is another <i>QObject</i> or the <i>QApplication</i> (the top-level Qt object). If you are instantiating a pipeline with no obvious parent, such as in the unittest code, then the function <i>CCP4Modules.QTAPPLICATION()</i> can be used to get the <i>QApplication</i> that can be used as a parent.</p>
<a name="file_organisation"><h5>File Organisation</h5>
<p>The objective is to have everything for one project in one place and to allow the pipeline developer as much flexibility as possible but to have some minimal organisation so 'the system' can find the 'plugins' and other developers can use the resources.</p> 
<p>I suggest the following (but this is totally up for discussion):
<br/>The wrappers for individual programs are in the <i>wrappers</i> directory where they are a resource for all developers and we avoid duplication of effort.
<br/>The 'pipelines' go in a separate <i>pipelines</i> directory that should contain sub-directories such as 'MrBump', 'CRANK' etc. Each of these projects contain the sub-directories:
<br/><i>script</i>: analogous to the <i>wrappers</i> directory this should contain, for example, a 'MrBump.py' file containing the MrBump class that is a sub-class of <i>CPluginScript</i>. The <i>script</i> directory could contain more than one script module - it is likely one pipeline development group might contribute more than one top level script.

<br/><i>utils</i> containing utility code that is part of the project but hopefully is available to other developers
<br><i>test_data</i> please provide all test data (er.. within reason)

<br/><i>gui</i>  containing (by analogy with the <i>tasks</i> directory) a file CTaskMrBump.py containing a CTaskMrBump class that is a sub-class of <i>CTaskWidget</i>.
<br/><i>docs</i> containing documentation</p>

<p>There is an alternative approach to this organisation: the project could provide a function or perhaps a 'resources' file that lists what resources (scripts, guis, docs) it wants to have 'published' in the overall ccp4i2 system. But, if it is not too onerous on pipeline developers, I think some standard organisation would help us to work together.</p>

<a name="process_manager"/><h5>The Process Manager</h5>
<p>The process manager currently just starts jobs on the local mchine but is intended in future to be the interface to access batch queues and remote resources etc.. There is one instance of a process manager for each Python process but note that if that process is a pipeline there may be many different plugins (instances of <i>CPluginScript</i>) run in that one Python process. The developer implementing a plugin should not normally need to access the process manager directly but the method <i>PROCESSMANAGER().getJobData()</i> may be used to retrieve information on a running job:</p>
<pre>
from core import CCP4Modules
status = CCP4Modules.PROCESSMANAGER().getJobData(pid=self.runningProcessId,attribute='exitStatus')
</pre>
<p>The pid is an integer and is i2's internal unique id for a process.<i> CPluginScript.runningProcessId</i> is the pid of the last process run by the plugin.  The attributes are listed below - a value of None will be returned if the attribute is not set.</p>
<table>
  <tr><td>command</td><td>string</td><td>The name of the executable</td></tr>
  <tr><td>arglist</td><td>list of strings</td><td>The arguments to the external program</td></tr>
  <tr><td>handler</td><td>Python command</td><td>Callback to be run after external process completed</td></tr>
  <tr><td>jobId</td><td>string</td><td>The i2 database job id (if provided)</td></tr>
  <tr><td>jobNumber</td><td>string</td><td>The i2 job number in the form n[.m[.i]] (if provided) </td></tr>
  <tr><td>ifAsync</td><td>Boolean</td><td>Flag if process is to run asynchronously</td></tr>
  <tr><td>timeout</td><td>float</td><td>The number of seconds to wait for completion of a job run in blocking mode</td></tr>
  <tr><td>editEnv</td><td>list of list of strings</td><td>A list of edits to subprocess environment</td></tr>
  <tr><td>inputFile</td><td>string</td><td>path to input command file</td></tr>
  <tr><td>logFile</td><td>string</td><td>path to ouput log file</td></tr>
  <tr><td>exitStatus</td><td>integer</td><td>0=OK,1=crashed</td></tr>
  <tr><td>exitCode</td><td>integer</td><td>exit code of the last process finished</td></tr>
  <tr><td>errorReport</td><td>CErrorReport</td><td>list of exceptions caught in running the process</td></tr>
  <tr><td>startTime</td><td>float</td><td>The machine processor time that process started</td></tr>
  <tr><td>finishTime</td><td>float</td><td>The machine processor time that process finished</td></tr>
  <tr><td>qprocess</td><td>Qt object</td><td>The QProcess that supported the external process (if this is used rather than subprocess)</td></tr>
</table>

<p>By default external processes are run in blocking mode, (<i>PROCESSMANAGER().startProcess()</i> does not return until the external process has completed. The <i>ifAsync</i> flag is set from the  <i>CPluginScript.async</i> flag and if that is True then <i>PROCESSMANAGER().startProcess()</i> will return immediately and the pipieline could possible start more jobs. The Process Manager will only start a limited number of asyncronous jobs at one time and will queue any excess requests to start when other processes finish.  The maximum number of processes is set in the file <i>$HOME/.CCP4I2/configs/ccp4i2_configs.params.xml</i>  as <i>maxRunningprocesses</i> parameter. (If the parameter is not in your file then delete the file so a new one is created.)  Note that if the user starts multiple tasks then there could be many more running processes.</p>
<p>The <i>editEnv</i> argument is a list of edits applied to the current environemnt. Each item in the list is a list. The first item in the sub-list is an environment variable name. If the sub-list is length 1 (just the environment variable name) then that environment variable is deleted; if the sublist is length 2 then the environment variable is set to the second item in the list.</p>

<a name="xml_files"><h5>XML Files</h5>
<p>All of the XML files used by CCP4i2 have the same basic structure, for example a parameter file..</p>

<pre>
&lt;?xml version='1.0' encoding='ASCII'?>
&lt;ccp4:ccp4i2 xmlns:ccp4="http://www.ccp4.ac.uk/ccp4ns">
  &lt;ccp4i2_header>
    &lt;function>PARAMS&lt;/function>
    &lt;ccp4iVersion>0.0.5&lt;ccp4iVersion>
    &lt;comment/>
    &lt;hostName>bilbo.chem.york.ac.uk&lt;/hostName>
    &lt;userId>lizp&lt;/userId>
    &lt;creationTime>11:06 20/Jun/14&lt;/creationTime>
    &lt;projectName>whokshop2&lt;/projectName>
    &lt;jobId>82d6e44af86211e39b3a3c0754185dfb&lt;/jobId>
    &lt;jobNumber>60&lt;/jobNumber>
    &lt;projectId>3a3041bdf16b11e38aeb3c0754185dfb&lt;/projectId>
    &lt;pluginName>prosmart_refmac&lt;/pluginName>
    &lt;pluginTitle>Refine with Prosmart-restrained Refmac&lt;/pluginTitle>
  &lt;/ccp4i2_header>
  &lt;ccp4i2_body>
    &lt;inputData>
      &lt;XYZIN>
          ....
  &lt;/ccp4i2_body>
&lt;/ccp4:ccp4i2>
</pre>

<p>Here the root element is <i>ccp4i2</i> with an <i>xmlns</i> attribute that gives the namespace as "http://www.ccp4.ac.uk/ccp4ns". The <i>ccp4i2</i> element has two sub-elements: <i>ccp4i2_header</i> which contains metadata and <i>ccp4i2_body</i> whose contents will depend of the type of file which is specified by the <i>function</i> element in the header.  The header usually contains details of the program version and source of the file (host,user, creation time) and, where appropriate, details of the project and job that the file is associated with. The header is usually written or read automatically by the  <i>CCP4File.CI2XmlHeader</i> class and developers should have little need to work directly with it.</p>
<p>There are some tools for handling XML files in CCP4i2. The Python library for <i>lxml</i> is included and has many tools which are described at <a href="http://lxml.de/index.html">lxml website</a>.  The internal representation of XML is as an <a href="lxml.de/tutorial.html">etree.Element</a> for which there is brief (but likely enough for ccp4i2 developers) documentation within the Python documentation <a href="http://docs.python.org/2/library/xml.etree.elementtree.html#module-xml.etree.ElementTree">here</a> (scroll down for Element). See also the comments in the CCP4i2 documentation for  <a href="./reports.html#xml">Reports</a>.  The <i>etree</i> functionality is used to build up an internal representation of XML which can be written to a file with the <i>CCP4Utils.saveEtreeToFile()</i> module.  An example to create a 'program' XML file in a CPluginScript:</p>
<pre>
      from lxml import etree
      from core import CCP4Utils
      # Create a 'root' element and add a 'mode' subElement
      rootEle = etree.Element('MYPROGRAM')
      modeEle = etree.SubElement(rootEle,'mode')
      modeEle.text = myMode

      # Load data from another XML file and append it to our tree
      try:
        otherXmlTree = CCP4Utils.openFileToEtree(..other-file-name..)
      except:
        # Report failure to read file
        self.appendErrorReport(110,other-file-name,stack=False)
      else:
        rootEle.append(otherXmlTree)

      # Save the xml tree to the 'PROGRAMXML' file
      CCP4Utils.saveEtreeToFile(rootEle,self.makeFileName('PROGRAMXML'))
</pre>


<hr>
<address></address>
<!-- hhmts start -->Last modified: Tue Sep 13 14:03:56 BST 2016 <!-- hhmts end -->
</body> </html>
